{"cells":[{"cell_type":"markdown","metadata":{"id":"TtZHYdlc3Ay4"},"source":["# Prepare notebook "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11579,"status":"ok","timestamp":1685904673918,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"Ec4r9DBB6Kt6","outputId":"d270a1a8-f1b7-4c2b-c6ff-d3257d3f2938","trusted":true},"outputs":[],"source":["!pip uninstall -y orbax flax dopamine-rl\n","!pip install \"numba<=0.56.0\"\n","!pip install librosa==0.9.2 timit-utils==0.9.0 torchaudio"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46294,"status":"ok","timestamp":1685904720183,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"412oOQOfwe85","outputId":"f2aae407-fedc-492c-972f-3f02dc1d44ef","trusted":true},"outputs":[],"source":["!pip install --upgrade tensorflow-addons==0.18.0\n","!pip install --upgrade tensorflow-probability==0.17.0\n","!pip install --upgrade tensorflow-io==0.26.0\n","!pip install --upgrade tensorflow==2.9.1\n","!pip install matplotlib==3.4\n","!pip install wandb==0.16\n","\n","!pip install -q opencv-python-headless librosa wandb scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T15:14:46.563925Z","iopub.status.busy":"2024-05-22T15:14:46.563495Z","iopub.status.idle":"2024-05-22T15:14:50.885026Z","shell.execute_reply":"2024-05-22T15:14:50.883919Z","shell.execute_reply.started":"2024-05-22T15:14:46.563892Z"},"trusted":true},"outputs":[],"source":["!pip install audiomentations"]},{"cell_type":"markdown","metadata":{"id":"1MnDWpSg3Olf"},"source":["## Import needed libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Hello\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:30:41.975162Z","iopub.status.busy":"2024-05-22T14:30:41.974804Z","iopub.status.idle":"2024-05-22T14:30:55.786664Z","shell.execute_reply":"2024-05-22T14:30:55.785845Z","shell.execute_reply.started":"2024-05-22T14:30:41.975124Z"},"executionInfo":{"elapsed":5674,"status":"ok","timestamp":1685904725845,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"KlPyGw5wzRqH","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","pd.options.mode.chained_assignment = None # avoids assignment warning\n","import numpy as np\n","import random\n","from glob import glob\n","from tqdm import tqdm \n","tqdm.pandas()  # enable progress bars in pandas operations\n","import gc\n","\n","import librosa\n","import sklearn\n","import json\n","\n","# Import for visualization\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import librosa.display as lid \n","import IPython.display as ipd\n","\n","# Import tensorflow\n","import tensorflow as tf\n","# Set logging level to avoid unnecessary messages\n","tf.get_logger().setLevel('ERROR') \n","# Set autograph verbosity to avoid unnecessary messages\n","tf.autograph.set_verbosity(0) \n","# Enable xla for speed up\n","tf.config.optimizer.set_jit(True)\n","\n","# Import required tensorflow modules\n","import tensorflow_io as tfio\n","import tensorflow_addons as tfa \n","import tensorflow_probability as tfp \n","import tensorflow.keras.backend as K \n","\n","print(\"Packages loaded\")"]},{"cell_type":"markdown","metadata":{"id":"d_Ckg5ZJ3qzH"},"source":["## Create CFG class to store all hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T15:04:17.454029Z","iopub.status.busy":"2024-05-22T15:04:17.453647Z","iopub.status.idle":"2024-05-22T15:04:17.465445Z","shell.execute_reply":"2024-05-22T15:04:17.464722Z","shell.execute_reply.started":"2024-05-22T15:04:17.453997Z"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685904772975,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"yd6-NZCOzgx-","trusted":true},"outputs":[],"source":["class CFG:\n","    \n","    # Plot training history\n","    training_plot = True\n","    \n","    # Notebook link\n","    notebook_link = 'kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification'\n","    \n","    # Verbosity level\n","    verbose = 2\n","    \n","    # Device and random seed\n","    device = 'GPU' \n","    seed = 21 # 42\n","    \n","    # Spectrogram size and batch size\n","    img_size = [64, 1292]\n","    batch_size = 32\n","    \n","    # Drop remainder - dropping last batch if size < batch size\n","    drop_remainder = True\n","    \n","    # TRAINING SETTINGS\n","    # Number of epochs, and number of folds\n","    epochs = 50\n","    fsr = True # reduce stride of stem block\n","    num_fold = 5\n","    \n","    # Selected folds for training and evaluation\n","    selected_folds = [0]\n","\n","    # Learning rate, optimizer, and scheduler\n","    lr = 1e-4 # 1e-3\n","    scheduler = 'cos'\n","    optimizer = 'Adam' # AdamW, Adam\n","    \n","    # Loss function and label smoothing\n","    loss = 'CCE' # BCE, CCE\n","    label_smoothing = 0.05 # label smoothing\n","    \n","    # AUDIO FILES CONFIGURATION\n","    duration = 30 # second\n","    sample_rate = 22050\n","    audio_len = duration*sample_rate\n","    \n","    # STFT parameters \n","    # taken from: https://ieeexplore-1ieee-1org-10000470f00e3.wbg2.bg.agh.edu.pl/stamp/stamp.jsp?tp=&arnumber=9778067\n","    window = 1024\n","    hop_length = 512\n","    nfft = 4096\n","    n_mels=64\n","    fmin = 0\n","    fmax = 8000\n","    normalize = True\n","    \n","    # AUGMENTATION CONFIG\n","    augment=True\n","    \n","    \n","    \n","    # SPECTROGRAM AUGMENTATION\n","    spec_augment_prob = 1 # IMPORTANT: SHOULD BE 1\n","    \n","    # Mix-Up augmentation\n","    mixup_prob = 0.2 # 0.4\n","    mixup_alpha = 0.5\n","    \n","    # Cut-Mix augmentation\n","    cutmix_prob = 0 # 0.3\n","    cutmix_alpha = 1\n","    \n","    # Frequency and Time masking\n","    mask_prob = 0.4 # 0.4\n","    freq_mask = 30\n","    time_mask = 30\n","\n","\n","    \n","    # AUGIO AUGMENTATION\n","    audio_augment_prob = 1 # IMPORTANT: SHOULD BE 1\n","    \n","    # Time shift\n","    timeshift_prob = 0.5 # 0.5\n","    \n","    # Gaussian Noise\n","    gn_prob = 0 # 0.3 \n","\n","    # Pitch Shift\n","    pitch_shift_prob = 1\n","    \n","    # Speed Change\n","    speed_change_prob = 0\n","    \n","    \n","    # Data Preprocessing Settings\n","    labelsMapping = {0: 'blues',\n","                 1: 'classical',\n","                 2: 'country',\n","                 3: 'disco',\n","                 4: 'hiphop',\n","                 5: 'jazz',\n","                 6: 'metal',\n","                 7: 'pop',\n","                 8: 'reggae',\n","                 9: 'rock'}\n","\n","    class_names = list(labelsMapping.values())\n","    num_classes = len(class_names)\n","    class_labels = list(range(num_classes))\n","    label2name = dict(zip(class_labels, class_names))\n","    name2label = {v:k for k,v in label2name.items()}\n","    \n","    # Paths\n","    DESTINATION_PATH = 'working\\\\' # ON KAGGLE: \"/kaggle/working/Music-Genres-Classification/\"\n","    DATA_DIRECTORY = 'gtzan\\\\Data\\\\' # ON KAGGLE: '/kaggle/input/gtzan-1000/Data/'\n","\n","    NETWORK_NAME = \"ResNet\"\n","    \n","# Set seeding\n","\n","def seeding(SEED):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    tf.random.set_seed(SEED)\n","    print('seeding done!!!')\n","    \n","seeding(CFG.seed)"]},{"cell_type":"markdown","metadata":{"id":"bjymKWqywzGt"},"source":["# Load data"]},{"cell_type":"markdown","metadata":{"id":"maA3jzK9w7d4"},"source":["## Unzip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:34.625938Z","iopub.status.busy":"2024-05-22T14:31:34.625228Z","iopub.status.idle":"2024-05-22T14:31:34.682605Z","shell.execute_reply":"2024-05-22T14:31:34.681955Z","shell.execute_reply.started":"2024-05-22T14:31:34.625902Z"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685904772976,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"BTPKrORZx65C","outputId":"da9e55b3-32ef-4393-b6b9-9f997caf9282","trusted":true},"outputs":[],"source":["os.listdir(CFG.DATA_DIRECTORY)"]},{"cell_type":"markdown","metadata":{"id":"HEJhxHHL3yn_"},"source":["## Set seeding"]},{"cell_type":"markdown","metadata":{"id":"P0VpRgBD31Ts"},"source":["## Prepare filepath | genre dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:35.770101Z","iopub.status.busy":"2024-05-22T14:31:35.769398Z","iopub.status.idle":"2024-05-22T14:31:36.747433Z","shell.execute_reply":"2024-05-22T14:31:36.746725Z","shell.execute_reply.started":"2024-05-22T14:31:35.770064Z"},"executionInfo":{"elapsed":3957,"status":"ok","timestamp":1685904907397,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"3TrDC9-O1tIt","trusted":true},"outputs":[],"source":["genres = sorted(os.listdir(CFG.DATA_DIRECTORY + \"genres_original\"))\n","\n","df = pd.DataFrame(columns=[\"filepath\", \"genre\"])\n","\n","idx = 0\n","for genre in genres:\n","    for audio in sorted(os.listdir(CFG.DATA_DIRECTORY + \"genres_original/\" + genre)):\n","        new_row = pd.DataFrame({\"filepath\": CFG.DATA_DIRECTORY + \"genres_original/\" + genre + \"/\" + audio,\n","                                \"genre\": genre}, \n","                               index=[idx])\n","        idx += 1\n","        df = pd.concat([df, new_row], ignore_index=True)\n","\n","df = df[df.filepath != CFG.DATA_DIRECTORY + \"genres_original/\" + \"jazz/jazz.00054.wav\"]\n","df['target'] = df.genre.map(CFG.name2label)"]},{"cell_type":"markdown","metadata":{"id":"oaS7MEBp38dO"},"source":["## Check if the path exists"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:37.721980Z","iopub.status.busy":"2024-05-22T14:31:37.721144Z","iopub.status.idle":"2024-05-22T14:31:37.727061Z","shell.execute_reply":"2024-05-22T14:31:37.726353Z","shell.execute_reply.started":"2024-05-22T14:31:37.721944Z"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1685904907399,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"W6k60alf2qfH","outputId":"7a9860aa-1968-405b-ffbd-8cc556ea129f","trusted":true},"outputs":[],"source":["tf.io.gfile.exists(df.filepath.iloc[0])"]},{"cell_type":"markdown","metadata":{},"source":["# Login to WANDB to log trainings"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import wandb\n","\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")\n","\n","wandb_config={\n","    \"architecture\": CFG.NETWORK_NAME,\n","    \"input_shape\": (64, 1292, 3),\n","    \"epochs\": CFG.epochs,\n","    \"batch_size\": CFG.batch_size,\n","    \"seed\": CFG.seed,\n","    \"use_small_sample\": False, \n","}\n","\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"mgc-augmentation\",\n","\n","    # track hyperparameters and run metadata with wandb.config\n","    config=wandb_config\n",")\n","    \n","wandb.log({\n","    \"Augment\": CFG.augment,\n","    \"Timeshift Prob\": CFG.timeshift_prob,\n","    \"Gaussian Noise Prob\": CFG.gn_prob,\n","    \"PitchShift Prob\": CFG.pitch_shift_prob,\n","    \"SpeedChange Prob\": CFG.speed_change_prob,\n","    \"Mixup Prob\": CFG.mixup_prob,\n","    \"MixUp Alpha\": CFG.mixup_alpha,\n","    \"CutMix Prob\": CFG.cutmix_prob,\n","    \"CutMix Alpha\": CFG.cutmix_alpha,\n","    \"Masking Prob\": CFG.mask_prob,\n","    \"Mask Width\": CFG.freq_mask\n","})"]},{"cell_type":"markdown","metadata":{"id":"zsa3CMlW4BCA"},"source":["# EDA"]},{"cell_type":"markdown","metadata":{"id":"WcwLK89oHKPQ"},"source":["## Utils to load and display sample audio, waveform and spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:42.437349Z","iopub.status.busy":"2024-05-22T14:31:42.436849Z","iopub.status.idle":"2024-05-22T14:31:43.207865Z","shell.execute_reply":"2024-05-22T14:31:43.207158Z","shell.execute_reply.started":"2024-05-22T14:31:42.437316Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685905424853,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"V_mbvBZL4B51","trusted":true},"outputs":[],"source":["import cv2\n","\n","def load_audio(filepath):\n","    audio, sr = librosa.load(filepath)\n","    return audio, sr\n","\n","def get_spectrogram(audio):\n","    spec = librosa.feature.melspectrogram(y=audio, \n","                                          sr=CFG.sample_rate, \n","                                          n_mels=CFG.n_mels,\n","                                          n_fft=CFG.nfft,\n","                                          hop_length=CFG.hop_length,\n","                                          # fmax=CFG.fmax,\n","                                          # fmin=CFG.fmin,\n","                                   )\n","    spec = librosa.power_to_db(spec, ref=np.max)\n","    return spec\n","\n","def display_audio(row):\n","    # Caption for viz\n","    caption = f'Id: {row.filepath} | Genre: {row.genre} | Target: {row.target}'\n","\n","    # Read audio file\n","    audio, sr = load_audio(row.filepath)\n","    # Keep fixed length audio\n","    audio = audio[:CFG.audio_len]\n","    # Spectrogram from audio\n","    spec = get_spectrogram(audio)\n","    # Display audio\n","    print(\"# AUDIO:\")\n","    display(ipd.Audio(audio, rate=CFG.sample_rate))\n","\n","    print(caption)\n","    print('# VISUALIZATION:')\n","    \n","    fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True, tight_layout=True)\n","\n","    # Waveplot\n","    lid.waveshow(audio,\n","                 sr=CFG.sample_rate,\n","                 ax=ax[0])\n","    # Specplot\n","    lid.specshow(spec, \n","                 sr = CFG.sample_rate,\n","                 hop_length = CFG.hop_length,\n","                 n_fft=CFG.nfft,\n","                #  fmin=CFG.fmin,\n","                #  fmax=CFG.fmax,\n","                 x_axis = 'time', \n","                 y_axis = 'mel',\n","                 cmap = 'coolwarm',\n","                 ax=ax[1])\n","    ax[0].set_xlabel('');\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4vLc-IX5HSna"},"source":["## Display samples"]},{"cell_type":"markdown","metadata":{"id":"0pN8V5-LHiWx"},"source":["### Blues"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:45.014869Z","iopub.status.busy":"2024-05-22T14:31:45.014527Z","iopub.status.idle":"2024-05-22T14:31:47.166132Z","shell.execute_reply":"2024-05-22T14:31:47.165356Z","shell.execute_reply.started":"2024-05-22T14:31:45.014842Z"},"executionInfo":{"elapsed":15420,"status":"ok","timestamp":1685905444589,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"ViaEJWEF4biJ","outputId":"8076f8b1-d09e-429f-c2e3-7a6e39fbbd4f","trusted":true},"outputs":[],"source":["class_name = CFG.class_names[0]\n","print(f'# Category: {class_name}')\n","class_df = df.query(\"genre==@class_name\")\n","print(f'# Num Samples: {len(class_df)}')\n","row = class_df.sample(1).squeeze()\n","\n","print(row['filepath'])\n","# Display audio\n","display_audio(row)"]},{"cell_type":"markdown","metadata":{"id":"jr_CLBpqHYpB"},"source":["### Classical"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":105,"status":"ok","timestamp":1685905444590,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"ApWteGFu-Caq","outputId":"095c332e-83fd-4989-f5b0-f39a19b4bf7f","trusted":true},"outputs":[],"source":["class_name = \"classical\"\n","print(f'# Category: {class_name}')\n","class_df = df.query(\"genre==@class_name\")\n","print(f'# Num Samples: {len(class_df)}')\n","row = class_df.sample(1).squeeze()\n","\n","# Display audio\n","display_audio(row)"]},{"cell_type":"markdown","metadata":{"id":"ljLZN_IfHcqC"},"source":["### Hiphop"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6377,"status":"ok","timestamp":1685905450895,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"Wav1Pu_8-Hq_","outputId":"605d6694-9cfe-47ec-bc55-770e55668d11","trusted":true},"outputs":[],"source":["class_name = CFG.class_names[4]\n","print(f'# Category: {class_name}')\n","class_df = df.query(\"genre==@class_name\")\n","print(f'# Num Samples: {len(class_df)}')\n","row = class_df.sample(1).squeeze()\n","\n","# Display audio\n","display_audio(row)"]},{"cell_type":"markdown","metadata":{"id":"sHCAJnZgzg0w"},"source":["### Rock"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1685905450897,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"0uipjarLzkCu","outputId":"53e665bd-c321-4524-b500-7346f23c220f","trusted":true},"outputs":[],"source":["class_name = \"rock\"\n","print(f'# Category: {class_name}')\n","class_df = df.query(\"genre==@class_name\")\n","print(f'# Num Samples: {len(class_df)}')\n","row = class_df.sample(1).squeeze()\n","\n","# Display audio\n","display_audio(row)"]},{"cell_type":"markdown","metadata":{},"source":["## Display 10 waves"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:51.134458Z","iopub.status.busy":"2024-05-22T14:31:51.134133Z","iopub.status.idle":"2024-05-22T14:31:52.402049Z","shell.execute_reply":"2024-05-22T14:31:52.401306Z","shell.execute_reply.started":"2024-05-22T14:31:51.134429Z"},"trusted":true},"outputs":[],"source":["def display_wave(row, ax):\n","\n","    # Read audio file\n","    audio, sr = load_audio(row.filepath)\n","    # Keep fixed length audio\n","    audio = audio[:CFG.audio_len]\n","\n","    # Waveplot\n","    lid.waveshow(audio,\n","                 sr=CFG.sample_rate,\n","                 ax=ax)\n","\n","    ax.set_xlabel('');\n","    ax.set_title(row.genre)\n","    \n","\n","fig, axs = plt.subplots(3, 1)\n","rows = df.sample(3)\n","i = 0\n","for _, row in rows.iterrows():\n","    \n","    display_wave(row, axs[i])\n","    \n","    i += 1\n","\n","plt.suptitle(\"Samples from GTZAN dataset as waveplots\", fontsize=13)\n","plt.subplots_adjust(hspace=0.5)\n","fig.text(0.035, 0.5, 'Amplitude', ha='center', va='center', rotation='vertical')\n","fig.text(0.51, 0.03, 'time [s]', ha='center', va='center')\n","plt.show()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Uf0aRmYaHsKV"},"source":["# Split Data"]},{"cell_type":"markdown","metadata":{"id":"jGQHbvVk__tG"},"source":["# Train-Val-Test split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:54.276354Z","iopub.status.busy":"2024-05-22T14:31:54.276022Z","iopub.status.idle":"2024-05-22T14:31:54.288479Z","shell.execute_reply":"2024-05-22T14:31:54.287756Z","shell.execute_reply.started":"2024-05-22T14:31:54.276325Z"},"id":"V9dLS4jgAEsH","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","df = df.reset_index(drop=True)\n","\n","df[\"split\"] = -1\n","\n","Train, Test = train_test_split(df, test_size=0.3, stratify=df['genre'], random_state=CFG.seed)\n","Val, Test = train_test_split(Test, test_size=0.33, stratify=Test['genre'], random_state=CFG.seed)\n","\n","Train[\"split\"] = \"train\"\n","Val[\"split\"] = \"val\"\n","Test[\"split\"] = \"test\"\n","\n","df = pd.concat([Train, Val, Test])"]},{"cell_type":"markdown","metadata":{"id":"5GC6fOOBIVQn"},"source":["# Augment Data"]},{"cell_type":"markdown","metadata":{"id":"N4sJxWcXIWxI"},"source":["## Generate random number"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:31:55.810854Z","iopub.status.busy":"2024-05-22T14:31:55.810183Z","iopub.status.idle":"2024-05-22T14:31:55.815422Z","shell.execute_reply":"2024-05-22T14:31:55.814773Z","shell.execute_reply.started":"2024-05-22T14:31:55.810816Z"},"id":"zF4qrXwy_qnH","trusted":true},"outputs":[],"source":["# Generates random integer\n","def random_int(shape=[], minval=0, maxval=1):\n","    return tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.int32)\n","\n","\n","# Generats random float\n","def random_float(shape=[], minval=0.0, maxval=1.0):\n","    rnd = tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n","    return rnd"]},{"cell_type":"markdown","metadata":{"id":"FjohfYmiIZbC"},"source":["## Augment Audio"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T16:08:23.299637Z","iopub.status.busy":"2024-05-22T16:08:23.299222Z","iopub.status.idle":"2024-05-22T16:08:23.337299Z","shell.execute_reply":"2024-05-22T16:08:23.336269Z","shell.execute_reply.started":"2024-05-22T16:08:23.299602Z"},"id":"ZTVjRd8NF-le","trusted":true},"outputs":[],"source":["# Import required packages\n","import tensorflow as tf\n","\n","from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n","import numpy as np\n","\n","\n","# Define a function to crop or pad audio data to a target length\n","@tf.function\n","def CropOrPad(audio, target_len, pad_mode='constant'):\n","\n","    audio_len = audio.shape[0]\n","\n","    if audio_len < target_len:\n","        diff_len = (target_len - audio_len)\n","        pad1 = random_int([], minval=0, maxval=diff_len)\n","        pad2 = diff_len - pad1\n","        pad_len = [pad1, pad2]\n","        audio = tf.pad(audio, paddings=[pad_len], mode=pad_mode)\n","    elif audio_len > target_len:\n","        diff_len = (audio_len - target_len)\n","        idx = tf.random.uniform([], 0, diff_len, dtype=tf.int32)\n","        audio = audio[idx: (idx + target_len)]\n","    audio = tf.reshape(audio, [target_len])\n","    return audio\n","\n","\n","augmentation_pipeline = Compose([\n","        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n","        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n","        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n","        Shift(p=0.5),\n","    ])\n","\n","def AudioAug(audio_np):  \n","    return augmentation_pipeline(samples=audio_np, sample_rate=CFG.sample_rate)\n","\n","\n","@tf.function\n","def Normalize(data, min_max=True):\n","    MEAN = tf.math.reduce_mean(data)\n","    STD = tf.math.reduce_std(data)\n","    data = tf.math.divide_no_nan(data - MEAN, STD)\n","    if min_max:\n","        MIN = tf.math.reduce_min(data)\n","        MAX = tf.math.reduce_max(data)\n","        data = tf.math.divide_no_nan(data - MIN, MAX - MIN)\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"MpdT4OR9IbK2"},"source":["## Augment Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:32:00.868769Z","iopub.status.busy":"2024-05-22T14:32:00.868424Z","iopub.status.idle":"2024-05-22T14:32:00.887688Z","shell.execute_reply":"2024-05-22T14:32:00.886995Z","shell.execute_reply.started":"2024-05-22T14:32:00.868742Z"},"id":"xS50lbBBGiZG","trusted":true},"outputs":[],"source":["@tf.function\n","def Spec2Img(spec, num_channels=3):\n","\n","    if num_channels > 1:\n","        img = tf.tile(spec[..., tf.newaxis], [1, 1, num_channels])\n","    else:\n","        img = spec[..., tf.newaxis]\n","    return img\n","\n","# Convert img (H,W,3) to image (H,W)\n","@tf.function\n","def Img2Spec(img):\n","    # Extract 1st channel\n","    return img[..., 0]\n","\n","\n","# Randomly mask data in time and freq axis\n","@tf.function\n","def TimeFreqMask(spec, time_mask, freq_mask, prob=0.5):\n","    if random_float() < prob:\n","        spec = tfio.audio.freq_mask(spec, param=freq_mask)\n","        spec = tfio.audio.time_mask(spec, param=time_mask)\n","    return spec\n","\n","\n","# Applies augmentation to Spectrogram\n","def SpecAug(spec):\n","    spec = tf.transpose(Img2Spec(spec), perm=[1, 0])\n","    spec = TimeFreqMask(spec, time_mask=CFG.time_mask, freq_mask=CFG.freq_mask, prob=CFG.mask_prob)\n","    spec = tf.transpose(spec, perm=[1, 0])\n","    spec = Spec2Img(spec)\n","    return spec\n","\n","\n","def mixup_image_aug(images, labels, alpha=CFG.mixup_alpha):\n","    \n","    if random_float() > CFG.mixup_prob:\n","        return images, labels\n","    \n","    image_shape = tf.shape(images)\n","    label_shape = tf.shape(labels)\n","\n","    beta = tfp.distributions.Beta(alpha, alpha) \n","    lam = beta.sample(1)[0]\n","\n","    images = lam * images + (1 - lam) * tf.roll(images, shift=1, axis=0)\n","    labels = lam * labels + (1 - lam) * tf.roll(labels, shift=1, axis=0)\n","\n","    images = tf.reshape(images, image_shape)\n","    labels = tf.reshape(labels, label_shape)\n","    \n","    return images, labels\n","\n","import tensorflow as tf\n","\n","\n","\n","def create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size):\n","    # Create a grid of coordinates (height x width)\n","    x_coords = tf.range(height)\n","    y_coords = tf.range(width)\n","    Y, X = tf.meshgrid(y_coords, x_coords)\n","\n","    # Reshape the bounding box coordinates to make them broadcastable over the batch size\n","    bbx1 = tf.reshape(bbx1, [batch_size, 1, 1])\n","    bby1 = tf.reshape(bby1, [batch_size, 1, 1])\n","    bbx2 = tf.reshape(bbx2, [batch_size, 1, 1])\n","    bby2 = tf.reshape(bby2, [batch_size, 1, 1])\n","\n","    # Create the mask by comparing the coordinates\n","    mask = (X >= bbx1) & (X < bbx2) & (Y >= bby1) & (Y < bby2)\n","    mask = tf.cast(mask, tf.float32)  # Convert the mask to float32\n","    \n","    # Calculate ratio \n","    patch_area = tf.reduce_sum(mask, axis=[1, 2])  # Sum over height, width, and channels dimensions\n","    total_area = height * width\n","    ratio = patch_area / tf.cast(total_area, tf.float32)\n","    ratio = tf.expand_dims(ratio, -1)\n","    ratio = tf.tile(ratio, [1, 10])\n","    # Add the channel dimension\n","    mask = tf.expand_dims(mask, -1)\n","    # Tile the mask across the channel dimension\n","    mask = tf.tile(mask, [1, 1, 1, channels])\n","    \n","    \n","    return mask, ratio\n","\n","\n","def cutmix(images, labels, probability=0.5, alpha=1.0):\n","    # Only apply CutMix with the given probability\n","    if random_float() > probability:\n","        return images, labels\n","\n","    # Assume images is a 4D tensor of shape [batch_size, height, width, channels]\n","    shape = tf.shape(images)\n","    \n","    batch_size = shape[0]\n","    height = shape[1]\n","    width = shape[2]\n","    channels = shape[3]\n","    \n","    # Sample lambda and calculate patch dimensions\n","    beta = tfp.distributions.Beta(alpha, alpha)\n","    lambda_val = beta.sample(1)\n","\n","    cut_rat = tf.sqrt(1. - lambda_val)\n","    \n","    cut_w = tf.cast(width, tf.float32) * cut_rat\n","    cut_w = tf.cast(cut_w, tf.int32)  # Now, cut_w is an int32 tensor.\n","    \n","    cut_h = tf.cast(height, tf.float32) * cut_rat\n","    cut_h = tf.cast(cut_h, tf.int32)  # Now, cut_h is an int32 tensor.\n","    \n","    # Uniformly sample the center of the patch\n","    cx = tf.random.uniform([batch_size], minval=0, maxval=width, dtype=tf.int32)\n","    cy = tf.random.uniform([batch_size], minval=0, maxval=height, dtype=tf.int32)\n","    \n","    # Calculate the patch coordinates\n","    bbx1 = tf.clip_by_value(cx - cut_w // 2, 0, width)\n","    bby1 = tf.clip_by_value(cy - cut_h // 2, 0, height)\n","    bbx2 = tf.clip_by_value(cx + cut_w // 2, 0, width)\n","    bby2 = tf.clip_by_value(cy + cut_h // 2, 0, height)\n","    \n","#     # Create mask\n","    mask, ratio = create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size)\n","    indices = tf.random.shuffle(tf.range(batch_size))\n","    mixed_images = images * mask + tf.gather(images, indices) * (1 - mask)\n","\n","    # Mix the labels\n","    mixed_labels = labels * ratio + tf.gather(labels, indices) * (1 - ratio)\n","#     mixed_labels = labels\n","    \n","    return mixed_images, mixed_labels"]},{"cell_type":"markdown","metadata":{"id":"LYmjnmnJIeGU"},"source":["## Convert Audio to Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:32:03.678103Z","iopub.status.busy":"2024-05-22T14:32:03.677785Z","iopub.status.idle":"2024-05-22T14:32:03.685060Z","shell.execute_reply":"2024-05-22T14:32:03.684407Z","shell.execute_reply.started":"2024-05-22T14:32:03.678075Z"},"id":"agi3OqngHIwa","trusted":true},"outputs":[],"source":["# Compute Spectrogram from audio \n","@tf.function\n","def Audio2Spec(audio, spec_shape=CFG.img_size, sr=CFG.sample_rate, nfft=CFG.nfft, window=CFG.window, fmin=0, fmax=8000):\n","    \"\"\"\n","    Computes a Mel-scaled spectrogram from audio using TensorFlow and TensorFlow-IO.\n","    \"\"\"\n","    # Get the desired height and width of the spectrogram\n","    spec_height = spec_shape[0]\n","    spec_width = spec_shape[1]\n","    \n","    # Get the length of the audio and calculate the hop length for the STFT\n","    audio_len = tf.shape(audio)[0]\n","    hop_length = CFG.hop_length # tf.cast((audio_len // (spec_width - 1)), tf.int32) # sample rate * duration / spec width - 1 == 627\n","    \n","    # Compute the spectrogram and the Mel-scaled spectrogram using TensorFlow-IO\n","    spec = tfio.audio.spectrogram(audio, nfft=nfft, window=window, stride=hop_length)\n","    mel_spec = tfio.audio.melscale(spec, rate=sr, mels=spec_height, fmin=fmin, fmax=fmax) \n","    \n","    # Convert the Mel-scaled spectrogram to decibels and transpose it to keep it (mel, time)\n","    db_mel_spec = tfio.audio.dbscale(mel_spec, top_db=80)\n","    db_mel_spec = tf.transpose(db_mel_spec, perm=[1, 0])\n","    \n","    # If the spectrogram is larger than the desired shape, crop it\n","    if tf.shape(db_mel_spec)[1] > spec_width:\n","        db_mel_spec = db_mel_spec[:, :spec_width]\n","    \n","    # Reshape the spectrogram to the desired shape and return it\n","    db_mel_spec = tf.reshape(db_mel_spec, spec_shape)\n","    return db_mel_spec"]},{"cell_type":"markdown","metadata":{"id":"wL3Cl6SeJ65p"},"source":["## Audio and Spectrogram Decoders"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:32:04.924910Z","iopub.status.busy":"2024-05-22T14:32:04.924028Z","iopub.status.idle":"2024-05-22T14:32:04.933804Z","shell.execute_reply":"2024-05-22T14:32:04.933073Z","shell.execute_reply.started":"2024-05-22T14:32:04.924871Z"},"id":"m8KdMW09KXlY","trusted":true},"outputs":[],"source":["def audio_decoder(path, label=None, with_labels=True, dim=CFG.audio_len, CFG=CFG):\n","    def get_audio(filepath):\n","        file_bytes = tf.io.read_file(filepath)\n","        audio = tfio.audio.decode_wav(file_bytes, dtype=tf.int16) # decode .ogg file for .wave replace `decode_wav`\n","        audio = tf.cast(audio, tf.float32)\n","        audio = tf.squeeze(audio, axis=-1)\n","        if CFG.normalize:\n","            audio = Normalize(audio)\n","        return audio\n","        \n","    def get_target(target):          \n","        target = tf.reshape(target, [1])\n","        target = tf.cast(tf.one_hot(target, len(CFG.class_labels)), tf.float32) \n","        target = tf.reshape(target, [len(CFG.class_labels)])\n","        return target\n","\n","    def decode(path):\n","        audio = get_audio(path)\n","        audio = CropOrPad(audio, dim) # crop or pad audio to keep a fixed length\n","        audio = tf.reshape(audio, [dim])\n","        return audio\n","    \n","    def decode_with_labels(path, label):\n","        label = get_target(label)\n","        return decode(path), label\n","    if type(path) == str:\n","        return decode_with_labels(path, label) if with_labels else decode(path)\n","    return decode_with_labels(path.numpy(), label.numpy()) if with_labels else decode(path.numpy())\n","\n","\n","def spec_decoder(with_labels=True, dim=CFG.img_size, CFG=CFG):\n","    def decode(audio):\n","        spec = Audio2Spec(audio, spec_shape=dim, sr=CFG.sample_rate, \n","                          nfft=CFG.nfft, window=CFG.window, fmin=CFG.fmin,fmax=CFG.fmax)\n","        \n","        # Spectrogram (H, W) to Image (H, W, C)\n","        spec = Spec2Img(spec, num_channels=3) \n","        spec = tf.reshape(spec, [*dim, 3])\n","        return spec\n","    \n","    def decode_with_labels(path, label):\n","        return decode(path), label\n","    \n","    return decode_with_labels if with_labels else decode"]},{"cell_type":"markdown","metadata":{"id":"GyBkqLPjf8oV"},"source":["## Augmenters\n","\n","Decide wheater to use augmentation for a given sample"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T16:11:51.241311Z","iopub.status.busy":"2024-05-22T16:11:51.240841Z","iopub.status.idle":"2024-05-22T16:11:51.250402Z","shell.execute_reply":"2024-05-22T16:11:51.249493Z","shell.execute_reply.started":"2024-05-22T16:11:51.241276Z"},"id":"xiSk1pDtffg5","trusted":true},"outputs":[],"source":["def audio_augmenter(with_labels=True, dim=CFG.audio_len, CFG=CFG):\n","    def augment(audio, dim=dim):\n","        def augment_audio(audio_tensor):\n","            audio_np = audio_tensor.numpy()  # Convert to NumPy array\n","            if random.random() <= CFG.audio_augment_prob:  # Ensure you import random\n","                audio_np = AudioAug(audio_np)\n","            return np.array(audio_np, dtype=np.float32)  # Convert back to NumPy array\n","        \n","        augmented_audio = tf.py_function(augment_audio, [audio], tf.float32)\n","        augmented_audio.set_shape([dim])\n","        return augmented_audio\n","    \n","    def augment_with_labels(audio, label):\n","        return augment(audio), label\n","    \n","    return augment_with_labels if with_labels else augment\n","\n","\n","def spec_augmenter(with_labels=True, dim=CFG.img_size, CFG=CFG):\n","    def augment(spec, dim=dim): \n","        if random_float() <= CFG.spec_augment_prob:\n","            spec = SpecAug(spec)\n","        spec = tf.reshape(spec, [*dim, 3])\n","        return spec\n","    \n","    def augment_with_labels(spec, label):    \n","        return augment(spec), label\n","    \n","    return augment_with_labels if with_labels else augment"]},{"cell_type":"markdown","metadata":{"id":"UkrQtU9EgnOs"},"source":["# Data Pipeline "]},{"cell_type":"markdown","metadata":{"id":"ptEpoionxrON"},"source":["## Specify data pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T16:07:18.291915Z","iopub.status.busy":"2024-05-22T16:07:18.291497Z","iopub.status.idle":"2024-05-22T16:07:18.307979Z","shell.execute_reply":"2024-05-22T16:07:18.307285Z","shell.execute_reply.started":"2024-05-22T16:07:18.291886Z"},"id":"jlEvBEQagoiC","trusted":true},"outputs":[],"source":["def build_dataset(paths, labels=None, batch_size=32, target_size=CFG.img_size, \n","                  audio_decode_fn=None, audio_augment_fn=None, \n","                  spec_decode_fn=None, spec_augment_fn=None,\n","                  cache=True, cache_dir=\"\",drop_remainder=False,\n","                  augment=True, repeat=True, shuffle=100):\n","    \"\"\"\n","    Creates a TensorFlow dataset from the given paths and labels.\n","    \n","    Args:\n","        paths (list): A list of file paths to the audio files.\n","        labels (list): A list of corresponding labels for the audio files.\n","        batch_size (int): Batch size for the created dataset.\n","        target_size (list): A list of target image size for the spectrograms.\n","        audio_decode_fn (function): A function to decode the audio file.\n","        audio_augment_fn (function): A function to augment the audio file.\n","        spec_decode_fn (function): A function to decode the spectrogram.\n","        spec_augment_fn (function): A function to augment the spectrogram.\n","        cache (bool): Whether to cache the dataset or not.\n","        cache_dir (str): Directory path to cache the dataset.\n","        drop_remainder (bool): Whether to drop the last batch if it is smaller than batch_size.\n","        augment (bool): Whether to augment the dataset or not.\n","        repeat (bool): Whether to repeat the dataset or not.\n","        shuffle (int): Number of elements from the dataset to buffer for shuffling.\n","        \n","    Returns:\n","        ds (tf.data.Dataset): A TensorFlow dataset.\n","    \"\"\"\n","    \n","    # Create cache directory if cache is enabled\n","    if cache_dir != \"\" and cache is True:\n","        os.makedirs(cache_dir, exist_ok=True)\n","\n","    # Set default functions if not provided\n","    if audio_decode_fn is None:\n","        audio_decode_fn = audio_decoder\n","\n","    if audio_augment_fn is None:\n","        audio_augment_fn = audio_augmenter(\n","            labels is not None, dim=CFG.audio_len, CFG=CFG)\n","\n","    if spec_decode_fn is None:\n","        spec_decode_fn = spec_decoder(\n","            labels is not None, dim=CFG.img_size, CFG=CFG)\n","\n","    if spec_augment_fn is None:\n","        spec_augment_fn = spec_augmenter(\n","            labels is not None, dim=CFG.img_size, CFG=CFG)\n","\n","    AUTO = tf.data.experimental.AUTOTUNE\n","\n","\n","    slices = paths if labels is None else (paths, labels)\n","    \n","    ds = tf.data.Dataset.from_tensor_slices(slices)\n","    \n","    def audio_decode_wrapper(x, y=None):\n","        if y is None:\n","            audio = tf.py_function(audio_decode_fn, [x], [tf.float32])\n","            # audio.set_shape([64, 1292, 3])\n","            return audio\n","        else:\n","            audio, label = tf.py_function(audio_decode_fn, [x, y], [tf.float32, tf.float32])\n","            # audio.set_shape([64, 1292, 3])\n","            # label.set_shape([32, 10])  # Adjust this according to the actual label shape\n","            return audio, label\n","    \n","    if labels is None:\n","        ds = ds.map(lambda x: audio_decode_wrapper(x), num_parallel_calls=AUTO)\n","    else:\n","        ds = ds.map(lambda x, y: audio_decode_wrapper(x, y), num_parallel_calls=AUTO)\n","\n","\n","    ds = ds.cache(cache_dir) if cache else ds\n","\n","    ds = ds.repeat() if repeat else ds\n","\n","    opt = tf.data.Options()\n","\n","    if shuffle: \n","        ds = ds.shuffle(shuffle, seed=CFG.seed)\n","        opt.experimental_deterministic = False\n","\n","    if CFG.device=='GPU':\n","        opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","\n","    ds = ds.with_options(opt)\n","\n","    ds = ds.map(audio_augment_fn, num_parallel_calls=AUTO) if augment else ds\n","\n","    ds = ds.map(spec_decode_fn, num_parallel_calls=AUTO)\n","\n","    ds = ds.map(spec_augment_fn, num_parallel_calls=AUTO) if augment else ds\n","\n","    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n","    \n","    ds = ds.map(mixup_image_aug, num_parallel_calls=AUTO) if augment else ds # if (augment and labels is not None) else ds\n","    ds = ds.map(lambda images, labels: cutmix(images, labels, probability=CFG.cutmix_prob, alpha=CFG.cutmix_alpha), num_parallel_calls=AUTO) if augment else ds\n","\n","\n","    ds = ds.prefetch(AUTO)\n","    return ds"]},{"cell_type":"markdown","metadata":{"id":"wKGPTiaNkvf0"},"source":["## Utils for Visualization of Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T14:32:11.638250Z","iopub.status.busy":"2024-05-22T14:32:11.637411Z","iopub.status.idle":"2024-05-22T14:32:11.649800Z","shell.execute_reply":"2024-05-22T14:32:11.649117Z","shell.execute_reply.started":"2024-05-22T14:32:11.638210Z"},"id":"LRJMVDFpg-wj","trusted":true},"outputs":[],"source":["def plot_batch(batch, row=3, col=3, filename=\"batch_plot.png\"):\n","    \"\"\"Plot one batch data\"\"\"\n","    if isinstance(batch, tuple) or isinstance(batch, list):\n","        imgs, tars = batch\n","    else:\n","        imgs = batch\n","        tars = None\n","        \n","    plt.figure(figsize=(col*5, row*3))\n","    for idx in range(row*col):\n","        ax = plt.subplot(row, col, idx+1)\n","        lid.specshow(imgs[idx][...,0].numpy(), \n","                     sr = CFG.sample_rate, \n","                     hop_length = CFG.hop_length,\n","                     fmin=CFG.fmin,\n","                     fmax=CFG.fmax,\n","                     x_axis = 'time', \n","                     y_axis = 'mel',\n","                     cmap = 'coolwarm')\n","        if tars is not None:\n","            label = tars[idx].numpy().argmax()\n","            name = CFG.label2name[label]\n","            plt.title(name)\n","    plt.tight_layout()\n","    plt.savefig(f'working\\\\{filename}', dpi=300, bbox_inches='tight') \n","    plt.show()\n","    \n","    \n","def plot_history(history):\n","    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n","    epochs = len(history.history['auc'])\n","    plt.figure(figsize=(15,5))\n","    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n","    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n","    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n","    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n","    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n","    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n","    plt.ylabel('Loss',size=14)\n","    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n","    plt.legend(loc=3)\n","    plt.show()  "]},{"cell_type":"markdown","metadata":{"id":"n82VL4p7lCK9"},"source":["### Visualize not augmented batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T15:40:43.349067Z","iopub.status.busy":"2024-05-22T15:40:43.348691Z","iopub.status.idle":"2024-05-22T15:40:51.527512Z","shell.execute_reply":"2024-05-22T15:40:51.526581Z","shell.execute_reply.started":"2024-05-22T15:40:43.349036Z"},"executionInfo":{"elapsed":18836,"status":"ok","timestamp":1685637430397,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"sA0qVm1HhBTp","outputId":"56c47db9-e014-486c-aa66-870ec70e9fc8","trusted":true},"outputs":[],"source":["ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=False, cache=False, shuffle=None)\n","ds = ds.take(100)\n","imgs, labels = next(iter(ds))\n","plot_batch((imgs, labels), row=3, col=4, filename=\"no_augmentation.png\")"]},{"cell_type":"markdown","metadata":{"id":"kKqlAmhDzFKR"},"source":["### Visualize augmented batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T16:25:05.264966Z","iopub.status.busy":"2024-05-22T16:25:05.262907Z"},"trusted":true},"outputs":[],"source":["ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=True, cache=False, shuffle=None)\n","ds = ds.take(100)\n","imgs, labels = next(iter(ds))\n","plot_batch((imgs, labels), row=3, col=4, filename=\"timeshift_augmentation.png\")"]},{"cell_type":"markdown","metadata":{"id":"LCpCcGA45xh9"},"source":["# Modelling utils"]},{"cell_type":"markdown","metadata":{"id":"NL0t4SNmzVGE"},"source":["## Define metrics, loss, optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LqW4GK653Rq","trusted":true},"outputs":[],"source":["import sklearn.metrics\n","\n","def get_metrics():\n","    auc = tf.keras.metrics.AUC(curve='PR', name='auc', multi_label=False) # auc on prcision-recall curve\n","    acc = tf.keras.metrics.CategoricalAccuracy(name='acc')\n","    return [acc, auc]\n","\n","def padded_cmap(y_true, y_pred, padding_factor=5):\n","    num_classes = y_true.shape[1]\n","    pad_rows = np.array([[1]*num_classes]*padding_factor)\n","    y_true = np.concatenate([y_true, pad_rows])\n","    y_pred = np.concatenate([y_pred, pad_rows])\n","    score = sklearn.metrics.average_precision_score(y_true, y_pred, average='macro',)\n","    return score\n","\n","def get_loss():\n","    if CFG.loss==\"CCE\":\n","        loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=CFG.label_smoothing)\n","    else:\n","        raise ValueError(\"Loss not found\")\n","    return loss\n","    \n","def get_optimizer():\n","    if CFG.optimizer == \"Adam\":\n","        opt = tf.keras.optimizers.Adam(learning_rate=CFG.lr)\n","    else:\n","        raise ValueError(\"Optmizer not found\")\n","    return opt"]},{"cell_type":"markdown","metadata":{"id":"Bka5cR_DbAIk"},"source":["## Train-Val-Test Fit function"]},{"cell_type":"markdown","metadata":{"id":"ymWfaipPcgLD"},"source":["## Save model and history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XmfEyfScjiF","trusted":true},"outputs":[],"source":["from datetime import datetime\n","import pickle\n","MODELS_PATH = CFG.DESTINATION_PATH + \"Models\"\n","\n","def save_model_and_history(model, history):\n","    # Create directory with name as current date\n","    date = str(datetime.now())\n","    path = os.path.join(MODELS_PATH, date)\n","\n","    # Create directory\n","    os.mkdir(path)\n","\n","    # Get model and history paths\n","    model_path = os.path.join(path, \"model.h5\")\n","    history_path = os.path.join(path, \"history.pkl\")\n","\n","    # Save model\n","    model.save(model_path)\n","\n","    # Save history\n","    with open(history_path, \"wb\") as f:\n","        pickle.dump(history.history, f)"]},{"cell_type":"markdown","metadata":{"id":"KSGRo-5TckEF"},"source":["## Load model and history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKU7fhJNcnl7","trusted":true},"outputs":[],"source":["def load_model_and_history(newness_number=1, model_directory=None):\n","    models = sorted(os.listdir(MODELS_PATH))\n","\n","    if model_directory: \n","        model_dir = os.path.join(MODELS_PATH, model_directory) \n","    else:\n","        model_dir = os.path.join(MODELS_PATH, models[-newness_number])\n","\n","    model = tf.keras.models.load_model(os.path.join(model_dir, \"model.h5\"))\n","\n","    with open(os.path.join(model_dir, \"history.pkl\"), 'rb') as json_file:\n","        # Load the JSON data as a dictionary\n","        history = pickle.load(json_file)\n","  \n","    return model, history"]},{"cell_type":"markdown","metadata":{"id":"TXaY_pgZcvEo"},"source":["## Plot learning curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsL-ItxicwRV","trusted":true},"outputs":[],"source":["def display_accuracy_curve(hist):\n","    plt.plot(hist[\"acc\"], label=\"accuracy\")\n","    plt.plot(hist[\"val_acc\"], label=\"val_accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.title(\"Learning curve\")\n","    plt.legend()\n","    plt.show()\n","\n","def display_loss_curve(hist):\n","    plt.plot(hist[\"loss\"], label=\"loss\")\n","    plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Learning curve\")\n","    plt.legend()\n","    plt.show()\n","\n","def display_auc_curve(hist):\n","    plt.plot(hist[\"auc\"], label=\"auc\")\n","    plt.plot(hist[\"val_auc\"], label=\"val_auc\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"AUC\")\n","    plt.title(\"Learning curve\")\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XM_yHi9Gd0u8"},"source":["## Plot confussion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWHefQiWd2Xu","trusted":true},"outputs":[],"source":["import itertools\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()\n","    plt.savefig(\"confusion_matrix.png\")\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ImS0MgcsXtK6"},"source":["## Predict genres"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6fPnnDGrKuW","trusted":true},"outputs":[],"source":["def predict_genres(model, paths):\n","    fake_labels = np.zeros(paths.shape, dtype=int)\n","    ds = build_dataset(paths, fake_labels,\n","                    batch_size=1, cache=False, shuffle=False,\n","                    augment=False, repeat=False, drop_remainder=False)\n","\n","    preds = model.predict(ds)\n","    pred_labels = np.argmax(preds, axis=1)\n","\n","    return pred_labels"]},{"cell_type":"markdown","metadata":{},"source":["## Log test dataset results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def log_test_metrics(test_labels, preds):\n","    accuracy = accuracy_score(test_labels, preds)\n","    precision = precision_score(test_labels, preds, average='weighted') \n","    recall = recall_score(test_labels, preds, average='weighted') \n","    f1 = f1_score(test_labels, preds, average='weighted')  \n","\n","\n","    wandb.log({\n","        \"Test Accuracy\": accuracy,\n","        \"Test Precision\": precision,\n","        \"Test Recall\": recall,\n","        \"Test F1 Score\": f1\n","    })\n","\n","    print(f\"Accuracy: {accuracy} Precision: {precision} Recall: {recall} F1: {f1}\")"]},{"cell_type":"markdown","metadata":{"id":"6y104ODXzaKz"},"source":["# EfficientNet"]},{"cell_type":"markdown","metadata":{"id":"8PCQVB6rzYNd"},"source":["## Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edh2_VDd56xw","trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.applications.efficientnet import EfficientNetB0\n","\n","def build_model(CFG, compile_model=True):\n","    \"\"\"\n","    Builds and returns a model based on the specified configuration.\n","    \"\"\"\n","\n","    DIM = (None, None)\n","\n","    # Base - EfficientNetB0              \n","    base = tf.keras.applications.EfficientNetB0(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","\n","    # Input layer\n","    inp = tf.keras.layers.Input(shape=(*DIM, 3))\n","\n","    # Input -> base\n","    out = base(inp)\n","\n","    # GAP layer\n","    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n","\n","    # Final dense layer for classiciation\n","    out = tf.keras.layers.Dense(32, activation='relu')(out)\n","    out = tf.keras.layers.BatchNormalization()(out)\n","    out = tf.keras.layers.Dropout(0.5)(out)\n","    \n","    out = tf.keras.layers.Dense(len(CFG.class_names), activation='softmax')(out)\n","\n","    # Create the TensorFlow model\n","    model = tf.keras.Model(inputs=inp, outputs=out)\n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8282,"status":"ok","timestamp":1685363767037,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"8SVyr0Pd7Oet","outputId":"cd718c2b-3793-4075-e0f5-f1891a7697bb","trusted":true},"outputs":[],"source":["model = build_model(CFG)\n","base_model_layer_names = [layer.name for layer in model.layers]\n","\n","for layer_name in base_model_layer_names:\n","    print(layer_name)\n","\n","out = model(imgs, training=False)\n","print(out.shape)\n","\n","print(model.summary())"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.applications.efficientnet import EfficientNetB0\n","\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","\n","def build_flattened_model_resnet(CFG, compile_model=True):\n","\n","    DIM = (None, None)\n","    # Load the base ResNet50 model without the top classification layers\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*DIM, 3))\n","\n","    # Make sure all layers are set to trainable for fine-tuning\n","    for layer in base_model.layers:\n","        layer.trainable = True\n","\n","    # Add custom layers on top of ResNet50\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(len(CFG.class_names), activation='softmax', name='output_layer')(x)  # Change the number of units and activation based on your task\n","\n","    # Create the complete model\n","    model = Model(inputs=base_model.input, outputs=x)\n","\n","    # Print the model summary\n","    \n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["m = build_flattened_model_resnet(CFG)\n","m.summary()"]},{"cell_type":"markdown","metadata":{"id":"qtKpYJHczreI"},"source":["## Check output shape"]},{"cell_type":"markdown","metadata":{"id":"3bJ6mXAL0G3n"},"source":["## Fit model in KFolds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Np-hyK1TbCBD","trusted":true},"outputs":[],"source":["from wandb.keras import WandbCallback\n","\n","\n","def train_val_test_fit(model, df, CFG, model_name=\"Model\"):\n","    # Split dataset with cv filter\n","    train_df = df.query(\"split == 'train'\").reset_index(drop=True) \n","    valid_df = df.query(\"split=='val'\").reset_index(drop=True) \n","\n","    # Get file paths and labels\n","    train_paths = train_df.filepath.values; train_labels = train_df.target.values\n","    valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n","\n","\n","    # Shuffle the file paths and labels\n","    index = np.arange(len(train_paths))\n","    np.random.shuffle(index)\n","    train_paths  = train_paths[index]\n","    train_labels = train_labels[index]\n","\n","    # Compute the number of training and validation samples\n","    num_train = len(train_paths); num_valid = len(valid_paths)\n","        \n","    # # Build the training and validation datasets\n","    cache=True\n","    train_ds = build_dataset(train_paths, train_labels, \n","                              batch_size=CFG.batch_size, cache=cache, shuffle=True,\n","                            augment=CFG.augment, drop_remainder=CFG.drop_remainder)\n","    valid_ds = build_dataset(valid_paths, valid_labels,\n","                              batch_size=CFG.batch_size, cache=cache, shuffle=False,\n","                              augment=False, repeat=False, drop_remainder=CFG.drop_remainder)\n","\n","\n","    # # Print information about the training\n","    print('#'*25); print('#### FOLD')\n","    print('#### Image Size: (%i, %i) | Model: %s | Batch Size: %i | Scheduler: %s'%\n","          (*CFG.img_size, model_name, CFG.batch_size, CFG.scheduler))\n","    print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n","\n","    # # Callbacks\n","    sv = tf.keras.callbacks.ModelCheckpoint(\n","        'training_save.keras', monitor='val_acc', verbose=0, save_best_only=True,\n","        save_weights_only=False, mode='max', save_freq='epoch')\n","    callbacks = [sv] # OPTIONALLY: WandbCallback(generator=valid_ds)\n","\n","    # # Training\n","    print('# Training')\n","    history = model.fit(\n","        train_ds, \n","        epochs=CFG.epochs, \n","        callbacks=callbacks, \n","        steps_per_epoch=len(train_paths)//CFG.batch_size,\n","        validation_data=valid_ds, \n","        # verbose=CFG.verbose,\n","    )\n","    \n","    model = tf.keras.models.load_model('working\\\\training_save.keras')\n","    \n","    return model, history"]},{"cell_type":"markdown","metadata":{"id":"DN79K4CLGXel"},"source":["## Fit model in TrainValTest"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5542485,"status":"ok","timestamp":1684937512284,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"4OnptRIFGaNX","outputId":"866b53da-a86f-44df-fa0e-9ba1c6afd4f9","trusted":true},"outputs":[],"source":[" # # Clear the session, build and train the model\n","K.clear_session()\n","# model = build_model(CFG)\n","model = build_flattened_model_resnet(CFG)\n","model, history = train_val_test_fit(model, df, CFG, model_name=\"ResNet\")"]},{"cell_type":"markdown","metadata":{"id":"lxt-rkgB0MI0"},"source":["## Save last model and history"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = tf.keras.models.load_model('/kaggle/working/training_save.h5')"]},{"cell_type":"markdown","metadata":{"id":"qtMK9XQJm6f3"},"source":["## Load last model and learning history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xi_Q89f9m52d","trusted":true},"outputs":[],"source":["# model, hist = load_model_and_history(model_directory=\"2023-05-24 14:12:31.673830\")"]},{"cell_type":"markdown","metadata":{"id":"B7yBtffJ06AF"},"source":["## Plot learning curves"]},{"cell_type":"markdown","metadata":{"id":"CiqQJpxX1DrO"},"source":["### Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":848,"status":"ok","timestamp":1685361079684,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"VLjM_WIHnDpH","outputId":"8b605d49-b589-464c-ca8c-8e24f7f28d10","trusted":true},"outputs":[],"source":["# display_accuracy_curve(hist)"]},{"cell_type":"markdown","metadata":{"id":"aipI9OHz1Fcs"},"source":["### Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1796,"status":"ok","timestamp":1685361083612,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"H01oM5fToOCE","outputId":"8a191a15-055c-472d-a0eb-9fa7cc71587b","trusted":true},"outputs":[],"source":["# display_loss_curve(hist)"]},{"cell_type":"markdown","metadata":{"id":"l4KZ0deW1H4L"},"source":["### AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2586,"status":"ok","timestamp":1685361086196,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"lZ0D_mnYoYM1","outputId":"0c716186-adcf-4357-c356-f71abfe1ce1d","trusted":true},"outputs":[],"source":["# display_auc_curve(hist)"]},{"cell_type":"markdown","metadata":{"id":"5Zn6Lz-roRs5"},"source":["## Predict on test set"]},{"cell_type":"markdown","metadata":{"id":"PLn42k4xouC9"},"source":["### Load test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jm3_n_E3oT0B","trusted":true},"outputs":[],"source":["test_df = df.query(\"split=='test'\").reset_index(drop=True)\n","test_paths = test_df.filepath.values; test_labels = test_df.target.values\n","\n","test_ds = build_dataset(test_paths, test_labels,\n","                          batch_size=1, cache=False, shuffle=False,\n","                          augment=False, repeat=False, drop_remainder=False)"]},{"cell_type":"markdown","metadata":{"id":"OcE-Y9TPovtO"},"source":["### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33031,"status":"ok","timestamp":1684937691953,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"Tt6mPrLSVnaV","outputId":"ec08ef59-c2c7-47c7-ac50-e2b655786cc3","trusted":true},"outputs":[],"source":["pred_labels = predict_genres(model, test_paths)\n","\n","log_test_metrics(test_labels, pred_labels)"]},{"cell_type":"markdown","metadata":{"id":"_CuTWCY4W_fY"},"source":["#### Accuracy score"]},{"cell_type":"markdown","metadata":{"id":"U82BaYHdXJTi"},"source":["#### Confussion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1211,"status":"ok","timestamp":1684937694602,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"1Fu36CIAXMPp","outputId":"a3146212-84db-4e57-f3da-d415b12d11ec","trusted":true},"outputs":[],"source":["cm = confusion_matrix(test_labels, pred_labels)\n","classes = list(CFG.labelsMapping.values())\n","\n","plot_confusion_matrix(cm, classes)\n","\n","wandb.log({\"Top 10 Confusion Matrix\": wandb.Image(\"confusion_matrix.png\")})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"cfDmRWUpXw_G"},"source":["# ResNet"]},{"cell_type":"markdown","metadata":{"id":"zAP_bkk0Xyrq"},"source":["## Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbRsHcHOX0o_","trusted":true},"outputs":[],"source":["# import efficientnet.tfkeras as efn\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","def build_model_resnet(CFG, compile_model=True):\n","    \"\"\"\n","    Builds and returns a model based on the specified configuration.\n","    \"\"\"\n","  \n","    DIM = (None, None)\n","\n","    # Base model - Resnet50\n","    base = tf.keras.applications.ResNet50(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","\n","    # Input layer \n","    inp = tf.keras.layers.Input(shape=(*DIM, 3))\n","\n","    # Input -> base \n","    out = base(inp)\n","\n","    # GAP Layer\n","    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n","\n","    # Final dense layer for classification\n","    out = tf.keras.layers.Dense(len(CFG.class_names), activation='softmax')(out)\n","\n","    # Create the TensorFlow model \n","    model = tf.keras.Model(inputs=inp, outputs=out)\n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGnui5nhxNb2","trusted":true},"outputs":[],"source":["def build_model_resnet_with_added_conv(CFG, compile_model=True):\n","    \"\"\"\n","    Builds and returns a model based on the specified configuration.\n","    \"\"\"\n","    \n","    DIM = (None, None)\n","\n","    # Base model - Resnet50\n","    base = tf.keras.applications.ResNet50(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","    \n","    # Input layer\n","    inp = tf.keras.layers.Input(shape=(*DIM, 3))\n","\n","    # Input -> base\n","    out = base(inp)\n","\n","    # Additional Conv2D layer\n","    out = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(out)\n","\n","    # GAP Layer\n","    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n","\n","    # Final dense layer for classification\n","    out = tf.keras.layers.Dense(len(CFG.class_names), activation='softmax')(out)\n","\n","    # Create the TensorFlow model \n","    model = tf.keras.Model(inputs=inp, outputs=out)\n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owlHcVtyXUPh","trusted":true},"outputs":[],"source":["m = build_model_resnet_with_added_conv(CFG)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685536379419,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"5ZHniAy2xRTF","outputId":"90995701-07c1-4557-86ae-062123aba66e","trusted":true},"outputs":[],"source":["m.summary()"]},{"cell_type":"markdown","metadata":{"id":"s9bj6GRsgtT-"},"source":["## Fit model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5371904,"status":"ok","timestamp":1685541755128,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"B8A-PoXtIflA","outputId":"c3a458ca-9ed6-422f-f691-a0f86c61a61f","trusted":true},"outputs":[],"source":["K.clear_session()\n","model = build_model_resnet(CFG)\n","model, history = train_val_test_fit(model, df, CFG, model_name=\"ResNet\")"]},{"cell_type":"markdown","metadata":{"id":"UYHKKnylehbS"},"source":["## Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oj73q1xkeiyW","trusted":true},"outputs":[],"source":["save_model_and_history(model, history)"]},{"cell_type":"markdown","metadata":{"id":"kdNiBp-cfZtb"},"source":["## Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVVzT-SzfceP","trusted":true},"outputs":[],"source":["model_resnet, hist_resnet = load_model_and_history(model_directory=\"2023-05-24 16:00:34.599873\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1685541781559,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"70zzh-YwWWci","outputId":"98dfe11a-3cbe-475d-91da-3b2f287e1b95","trusted":true},"outputs":[],"source":["model_resnet.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685529496021,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"gnGoYMaVhbWl","outputId":"504c35e8-1c13-4c9e-8d49-f049e943537f","trusted":true},"outputs":[],"source":["for elem in model_resnet.get_layer('resnet50').layers:\n","    print(elem.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685529526098,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"nNj29sTDYnH-","outputId":"e733cb0f-be6f-43be-be89-e8aa1b174b94","trusted":true},"outputs":[],"source":["model_resnet.get_layer('resnet50').get_layer('conv5_block3_out').output"]},{"cell_type":"markdown","metadata":{"id":"9tay6MRgfsWk"},"source":["## Plot learning curves"]},{"cell_type":"markdown","metadata":{"id":"Z7zOLec6fsWl"},"source":["### Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1684944128426,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"HeHlcktDfsWl","outputId":"9f6507c9-40a1-428b-b746-901b996db7fb","trusted":true},"outputs":[],"source":["display_accuracy_curve(hist_resnet)"]},{"cell_type":"markdown","metadata":{"id":"EcnuNRvEfsWl"},"source":["### Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":491,"status":"ok","timestamp":1684944128915,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"y2DNDs0GfsWl","outputId":"fe21537c-52f8-4369-a86b-3a60bc910695","trusted":true},"outputs":[],"source":["display_loss_curve(hist_resnet)"]},{"cell_type":"markdown","metadata":{"id":"-gugjh8WfsWl"},"source":["### AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1684944132687,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"VGdJ-xyPfsWl","outputId":"c9645baa-103d-4f38-8b91-48d6ccb93752","trusted":true},"outputs":[],"source":["display_auc_curve(hist_resnet)"]},{"cell_type":"markdown","metadata":{"id":"c9mTMwpef6Sv"},"source":["## Predict on test set"]},{"cell_type":"markdown","metadata":{"id":"5V1P_tVYf6Sv"},"source":["### Load test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_df = df.query(\"split=='val'\").reset_index(drop=True)\n","val_paths = val_df.filepath.values; val_labels = val_df.target.values\n","\n","val_ds = build_dataset(val_paths, val_labels,\n","                          batch_size=1, cache=False, shuffle=False,\n","                          augment=False, repeat=False, drop_remainder=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred_val_labels = predict_genres(model, val_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["log_test_metrics(pred_val_labels, val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ndc6iU5ef6Sv","trusted":true},"outputs":[],"source":["test_df = df.query(\"split=='test'\").reset_index(drop=True)\n","test_paths = test_df.filepath.values; test_labels = test_df.target.values\n","\n","test_ds = build_dataset(test_paths, test_labels,\n","                          batch_size=1, cache=False, shuffle=False,\n","                          augment=False, repeat=False, drop_remainder=False)"]},{"cell_type":"markdown","metadata":{"id":"wWqTTZXFf6Sw"},"source":["### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DKrzTBbf6Sw","trusted":true},"outputs":[],"source":["pred_labels = predict_genres(model, test_paths)\n","\n","log_test_metrics(test_labels, pred_labels)"]},{"cell_type":"markdown","metadata":{"id":"-yzWBobaf6Sw"},"source":["#### Accuracy score"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":462,"status":"ok","timestamp":1684944221363,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"P4lYZR7Vf6Sw","outputId":"d80ce96e-b411-4705-ff86-ec3472889be4","trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, pred_labels)"]},{"cell_type":"markdown","metadata":{"id":"cLPLGIvKf6Sw"},"source":["#### Confussion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1080,"status":"ok","timestamp":1684944228984,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"M2mP07h4f6Sw","outputId":"157ee35f-90a4-4bd0-cb49-32e8517c9734","trusted":true},"outputs":[],"source":["cm = confusion_matrix(test_labels, pred_labels)\n","classes = list(CFG.labelsMapping.values())\n","\n","plot_confusion_matrix(cm, classes)\n","\n","wandb.log({\"Top 10 Confusion Matrix\": wandb.Image(\"confusion_matrix.png\")})"]},{"cell_type":"markdown","metadata":{"id":"kSvR4vUMQ5Bw"},"source":["# Saliency maps\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Wznltimkij-U"},"source":["## Get last layer names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLXGynI5ii8k","trusted":true},"outputs":[],"source":["last_conv_layer_name_resnet = \"conv2d\""]},{"cell_type":"markdown","metadata":{"id":"TU5uF968iVga"},"source":["## Grad-CAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZDa944EYOvx","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from tensorflow.keras.utils import img_to_array, array_to_img\n","\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","\n","def save_and_display_gradcam(img_array, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n","    # Load the original image\n","    img = img_array\n","    # img = keras.preprocessing.image.load_img(img_path)\n","    # img = keras.preprocessing.image.img_to_array(img)\n","\n","    #img = cv2.resize(img, [150, 150])\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    \n","    superimposed_img = array_to_img(superimposed_img)\n","    return superimposed_img, img\n","\n","    # # Save the superimposed image\n","    # superimposed_img.save(cam_path)\n","\n","    # # Display Grad CAM\n","    # return Image(cam_path)"]},{"cell_type":"markdown","metadata":{"id":"APOIq1dViWh0"},"source":["### ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8478,"status":"ok","timestamp":1685637453955,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"egczGrlLH8l8","outputId":"ee875151-98c8-4d2a-e37c-435ef8a79461","trusted":true},"outputs":[],"source":["model_resnet, hist_resnet = load_model_and_history(model_directory=\"2023-05-31 14:02:35.553126\")\n","\n","model_resnet.summary()"]},{"cell_type":"markdown","metadata":{"id":"Igbt57qalf6O"},"source":["#### Util - Process audio, spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0b7tzlWh8Pj","trusted":true},"outputs":[],"source":["def preprocess_audio(path):\n","    file_bytes = tf.io.read_file(path)\n","    audio = tfio.audio.decode_wav(file_bytes, dtype=tf.int16) \n","    audio = tf.cast(audio, tf.float32)\n","    audio = tf.squeeze(audio, axis=-1)\n","    if CFG.normalize:\n","      audio = Normalize(audio)\n","\n","    audio = CropOrPad(audio, CFG.audio_len) \n","    audio = tf.reshape(audio, [CFG.audio_len])\n","\n","    return audio\n","\n","def preprocess_spectrogram(audio):\n","    spec = Audio2Spec(audio, spec_shape=CFG.img_size, sr=CFG.sample_rate, \n","                          nfft=CFG.nfft, window=CFG.window, fmin=CFG.fmin,fmax=CFG.fmax)\n","\n","    spec = Spec2Img(spec, num_channels=3) \n","    spec = tf.reshape(spec, [*CFG.img_size, 3])\n","\n","    return spec"]},{"cell_type":"markdown","metadata":{"id":"k7hOLi5jli5q"},"source":["#### Util - Show spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVEllWN3kOLz","trusted":true},"outputs":[],"source":["def show_spectrogram(spectrogram_tensor):\n","\n","    if isinstance(spectrogram_tensor,np.ndarray):\n","      lid.specshow(spectrogram_tensor[...,0], \n","                      sr = CFG.sample_rate, \n","                      hop_length = CFG.hop_length,\n","                      fmin=CFG.fmin,\n","                      fmax=CFG.fmax,\n","                      x_axis = 'time', \n","                      y_axis = 'mel',\n","                      cmap = 'coolwarm')\n","    else:\n","      lid.specshow(spectrogram_tensor[...,0].numpy(), \n","                      sr = CFG.sample_rate, \n","                      hop_length = CFG.hop_length,\n","                      fmin=CFG.fmin,\n","                      fmax=CFG.fmax,\n","                      x_axis = 'time', \n","                      y_axis = 'mel',\n","                      cmap = 'coolwarm')\n"]},{"cell_type":"markdown","metadata":{"id":"9BxtnPF2Jd5a"},"source":["#### Create function to compare spectrogram with CAM result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00RxKKHyD2g4","trusted":true},"outputs":[],"source":["from PIL import Image\n","\n","def display_cam_spectrogram(cam_image, image, main_title):\n","  \n","  # Create suptitle\n","  fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n","  plt.suptitle(f\"Music genre: {main_title}\")\n","\n","  # Stretch CAM Image\n","  stretched_image = cam_image.resize((500, 350))\n","  \n","  # Stretch Spectrogram, add Colormap\n","  image_rgb = image.convert(\"RGB\")\n","  image_array = np.array(image_rgb)\n","\n","  colormap = matplotlib.colormaps[\"coolwarm\"]\n","  colored_image_array = colormap(image_array[:, :, 0] / 255.0)  # Normalize the red channel\n","\n","  colored_image = Image.fromarray((colored_image_array[:, :, :3] * 255).astype(np.uint8))\n","\n","  # Display or save the colored image\n","  axs[0].imshow(colored_image.resize((500, 350)).rotate(180).transpose(Image.FLIP_LEFT_RIGHT))\n","  axs[0].set_title(\"Input Spectrogram\")\n","\n","  axs[1].imshow(stretched_image.rotate(180).transpose(Image.FLIP_LEFT_RIGHT))\n","  axs[1].set_title(\"CAM Visualization\")\n","\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"n_AxDNf022z-"},"source":["#### Choose random song from test set"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":866,"status":"ok","timestamp":1685640547903,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"8yO0cybh22z_","outputId":"024d5190-f134-49fe-951c-55fdc56b8619","trusted":true},"outputs":[],"source":["random_test_data = df.query(\"split == 'train'\").query(\"genre == 'rock'\").sample(1).squeeze()\n","\n","random_test_path = random_test_data[\"filepath\"]\n","random_test_label = random_test_data[\"target\"]\n","\n","print(f\"Song: {random_test_path}. Label: {random_test_label}\")"]},{"cell_type":"markdown","metadata":{"id":"SiXel_R-220A"},"source":["#### Process audio, process and display spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1477,"status":"ok","timestamp":1685640551585,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"eo9DIonH220A","outputId":"05f25688-ad48-4b08-8717-d8618000033b","trusted":true},"outputs":[],"source":["audio = preprocess_audio(random_test_path)\n","spec = preprocess_spectrogram(audio)\n","show_spectrogram(spec)"]},{"cell_type":"markdown","metadata":{"id":"MGTyo6zH220B"},"source":["#### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1685640552404,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"PKug85By220B","outputId":"7dc6923f-de5c-4c09-d369-fc6c0a6df213","trusted":true},"outputs":[],"source":["prediction_resnet = model_resnet.predict(np.expand_dims(spec, axis=0), verbose=0)\n","\n","print(f\"Resnet -- {CFG.labelsMapping[np.argmax(prediction_resnet)]} -- probability={np.max(prediction_resnet)}\")"]},{"cell_type":"markdown","metadata":{"id":"m3FwTeUNjZIu"},"source":["#### Heatmap and Grad-CAM"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":841,"status":"ok","timestamp":1685640558026,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"rHWHpgZBjl6L","outputId":"8849d502-692a-47f1-e66b-143c0936840d","trusted":true},"outputs":[],"source":["heatmap_resnet = make_gradcam_heatmap(spec, model_resnet, last_conv_layer_name_resnet)\n","gradcam_resnet, image = save_and_display_gradcam(spec, heatmap_resnet)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":858,"status":"ok","timestamp":1685640559206,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"VQiqNPEe4Lu0","outputId":"2ca1f040-582d-4495-eade-1f917728c6db","trusted":true},"outputs":[],"source":["OldRange = (np.max(image) - np.min(image))  \n","NewRange = 255 - 0\n","image = (((image - np.min(image)) * NewRange) / OldRange) + 0\n","\n","display_cam_spectrogram(gradcam_resnet, \n","                        Image.fromarray(image.numpy().astype(np.uint8)), \n","                        CFG.labelsMapping[np.argmax(prediction_resnet)])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685638332422,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"7sJuOYYc340D","outputId":"4394aff8-01e0-491d-8125-15dc067b48ad","trusted":true},"outputs":[],"source":["plt.imshow(gradcam_resnet)"]},{"cell_type":"markdown","metadata":{"id":"vGK4srOxkLPC"},"source":["#### Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1651,"status":"ok","timestamp":1685639463502,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"eQGV-2ExkMJ-","outputId":"f9a3fbd2-c57e-4a04-bdca-482d4ff4d1b2","trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(1, 2, figsize=(10,5))\n","axs[0].matshow(heatmap_resnet)\n","axs[0].set_title(f\"ResNet: {np.max(prediction_resnet)}\")\n","\n","axs[1].imshow(gradcam_resnet)\n","axs[1].set_title(f\"ResNet: {np.max(prediction_resnet)}\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ztZqdQQ2tGiS"},"source":["### CAM"]},{"cell_type":"markdown","metadata":{"id":"ANHqFdQOJWQN"},"source":["#### Functions used for CAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7LIbdp1tH9d","trusted":true},"outputs":[],"source":["import numpy as np\n","import cv2\n","from keras import backend as K\n","import matplotlib.cm as cm\n","import matplotlib\n","from tensorflow.keras.utils import img_to_array, array_to_img\n","\n","def get_class_activation_map(model, img,  last_conv_layer_name):\n","    ''' \n","    this function computes the class activation map\n","    \n","    Inputs:\n","        1) model (tensorflow model) : trained model\n","        2) img (numpy array of shape (224, 224, 3)) : input image\n","    '''\n","    \n","    # expand dimension - create batch of one image\n","    img = np.expand_dims(img, axis=0)\n","\n","    # predict the top class and get it's label\n","    predictions = model.predict(img, verbose=0)\n","    label_index = np.argmax(predictions)\n","    \n","    # Get the input weights to the softmax of all classes and then for the winning class.\n","    class_weights = model.layers[-1].get_weights()[0] # shape (num_of_neurons_in_dense, num_classes)\n","    class_weights_winner = class_weights[:, label_index] # (num_of_neurons_in_dense, )\n","\n","    # Get last Convolutional layer\n","    final_conv_layer = model.get_layer(last_conv_layer_name)\n","\n","    # Get all filters from last Conv layer (1, filt_size, filt_size, num_of_neurons)\n","    get_output = K.function([model.layers[0].input],[final_conv_layer.output, model.layers[-1].output])\n","    [conv_outputs, predictions] = get_output([img])\n","    \n","    # Squeeze conv map to shape image to size (filt_size, filt_size, num_of_neurons)\n","    conv_outputs = np.squeeze(conv_outputs)\n","\n","    # get class activation map for object class that is predicted to be in the image - multiply weights, maps and sum\n","    final_output = np.dot(cv2.resize(conv_outputs, dsize=(150, 150), interpolation=cv2.INTER_CUBIC), class_weights_winner).reshape(150,150) # dim: 224 x 224\n","    \n","    # return class activation map\n","    return final_output, label_index\n","\n","def save_and_display_cam(img_array, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n","    # Load the original image\n","    img = img_array\n","    # img = keras.preprocessing.image.load_img(img_path)\n","    # img = keras.preprocessing.image.img_to_array(img)\n","\n","    #img = cv2.resize(img, [150, 150])\n","    # Rescale heatmap to a range 0-255\n","    OldRange = (np.max(heatmap) - np.min(heatmap))  \n","    NewRange = 255 - 0\n","    heatmap = (((heatmap - np.min(heatmap)) * NewRange) / OldRange) + 0\n","    heatmap = np.uint8(heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = matplotlib.colormaps[\"jet\"]\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    \n","    superimposed_img = array_to_img(superimposed_img)\n","    return superimposed_img, array_to_img(img)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_rXtjzdmbyOK"},"source":["#### Choose random song from test set"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1685637905965,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"Hi4pZN6jaXBT","outputId":"5da6366f-69f8-4ad0-cfb4-e0c71cb9b336","trusted":true},"outputs":[],"source":["random_test_data = df.query(\"split == 'train'\").query(\"genre == 'pop'\").sample(1).squeeze()\n","\n","random_test_path = random_test_data[\"filepath\"]\n","random_test_label = random_test_data[\"target\"]\n","\n","print(f\"Song: {random_test_path}. Label: {random_test_label}\")"]},{"cell_type":"markdown","metadata":{"id":"O4Y2dAxPltzS"},"source":["#### Process audio, process and display spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1882,"status":"ok","timestamp":1685637909903,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"rmwHlNp6kjM6","outputId":"50d43d5b-aea4-4cfa-ad5c-2ef049a03963","trusted":true},"outputs":[],"source":["audio = preprocess_audio(random_test_path)\n","spec = preprocess_spectrogram(audio)\n","show_spectrogram(spec)"]},{"cell_type":"markdown","metadata":{"id":"dAYDyejljQW8"},"source":["#### Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685639107806,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"2Lc77fU-jHtz","outputId":"f8f8edef-aef1-4ae9-c5ae-a415173fd0e1","trusted":true},"outputs":[],"source":["prediction_resnet = model_resnet.predict(np.expand_dims(spec, axis=0), verbose=0)\n","\n","print(f\"Resnet -- {CFG.labelsMapping[np.argmax(prediction_resnet)]} -- probability={np.max(prediction_resnet)}\")"]},{"cell_type":"markdown","metadata":{"id":"wxEu6FVQJZBE"},"source":["#### Calculate Heatmaps and CAM Visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyRXKvLLtJaN","trusted":true},"outputs":[],"source":["final_output, label_index = get_class_activation_map(model_resnet, spec,  last_conv_layer_name_resnet)\n","cam_image, image = save_and_display_cam(spec, final_output, cam_path=\"cam.jpg\", alpha=0.4)"]},{"cell_type":"markdown","metadata":{"id":"1N2MH4i8JinQ"},"source":["#### Visualize CAM and spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1426,"status":"ok","timestamp":1685639111402,"user":{"displayName":"Kac Moty","userId":"09835526837253372594"},"user_tz":-120},"id":"VXh9pveFJF9_","outputId":"67cee9dc-39e9-40fa-b384-2bd7b69ad376","trusted":true},"outputs":[],"source":["display_cam_spectrogram(cam_image,\n","                        image,\n","                        CFG.labelsMapping[np.argmax(prediction_resnet)])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import wandb\n","\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")\n","\n","wandb.init(project='mgc-augmentation', \n","           entity='kmotyka2000org', \n","           id='5bhcwqps', \n","           resume='must')\n","\n","run = wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"mgc-augmentation\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","entity = \"kmotyka2000org\"\n","project = \"mgc-augmentation\"\n","artifact_name = \"model-prime-wildflower-20\"\n","epoch = \"latest\"\n","\n","artifact = run.use_artifact(f'{entity}/{project}/{artifact_name}:{epoch}')\n","\n","# Download the model\n","artifact_dir = artifact.download()\n","\n","# Load the model\n","model = tf.keras.models.load_model(artifact_dir)\n","\n","# model = tf.keras.models.load_model('/kaggle/input/no-aug-best/tensorflow2/no-aug-model/1/model-best.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = tf.keras.models.load_model('/kaggle/working/fold-0.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Close WANDB session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["IO49eqwxavOS"],"gpuType":"T4","provenance":[],"toc_visible":true},"gpuClass":"standard","kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"datasetId":4938332,"sourceId":8312854,"sourceType":"datasetVersion"}],"dockerImageVersionId":30700,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
