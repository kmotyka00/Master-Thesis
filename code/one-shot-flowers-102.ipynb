{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Oxford 102 Flowers"]},{"cell_type":"markdown","metadata":{},"source":["## Import packages, set configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:12:10.536899Z","iopub.status.busy":"2024-05-19T14:12:10.536585Z","iopub.status.idle":"2024-05-19T14:12:23.081968Z","shell.execute_reply":"2024-05-19T14:12:23.080872Z","shell.execute_reply.started":"2024-05-19T14:12:10.536870Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-19T16:40:27.109957Z","iopub.status.busy":"2024-05-19T16:40:27.109516Z","iopub.status.idle":"2024-05-19T16:40:27.142545Z","shell.execute_reply":"2024-05-19T16:40:27.141317Z","shell.execute_reply.started":"2024-05-19T16:40:27.109921Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import os\n","import matplotlib.pyplot as plt\n","import random\n","import json\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","from PIL import Image\n","import tensorflow.keras.backend as K\n","import tensorflow_probability as tfp\n","from scipy.stats import beta\n","import pickle \n","\n","class CFG:\n","    # Directories\n","    DIR_NAME = '/kaggle/input/pytorch-challange-flower-dataset/dataset/'\n","    TRAIN_DIR = os.path.join(DIR_NAME, 'train')\n","    VAL_DIR = os.path.join(DIR_NAME, 'valid')\n","    TEST_DIR = os.path.join(DIR_NAME, 'test')\n","    \n","    # Images\n","    CNN_INPUT_HEIGHT = 224\n","    CNN_INPUT_WIDTH = 224\n","    CNN_INPUT_SIZE = (CNN_INPUT_HEIGHT, CNN_INPUT_WIDTH)\n","    CNN_INPUT_CHANNELS = 3\n","    CNN_INPUT_SHAPE = (CNN_INPUT_HEIGHT, CNN_INPUT_WIDTH, CNN_INPUT_CHANNELS)\n","    \n","    # Categories\n","    CATEGORIES_JSON_PATH = '/kaggle/input/pytorch-challange-flower-dataset/cat_to_name.json'\n","    \n","    with open(CATEGORIES_JSON_PATH) as f:\n","        CATEGORIES = json.load(f)\n","    CATEGORIES = {int(k): v for k,v in CATEGORIES.items()}\n","    \n","    # Dataset\n","    BATCH_SIZE = 32\n","    TRAIN_SET_SIZE = 6552\n","    \n","    # Dataset Augmentation\n","    AUGMENT = True\n","    TRADITIONAL_AUG_PROB = 0.4\n","    \n","    MIXUP_PROB = 0.4\n","    MIXUP_ALPHA = 0.4\n","\n","    CUTMIX_PROB = 0.4\n","    CUTMIX_ALPHA = 1\n","    \n","    # Seeding\n","    SEED = 32\n","    \n","    # Model settings\n","    NETWORK_NAME = \"ResNet\"\n","    optimizer = \"Adam\"\n","    loss =\"CCE\"\n","    lr = 1e-5 # For Optimizer\n","    label_smoothing=0.0 # For loss (CCE)\n","    \n","    # Training\n","    NUM_SPLITS = 5\n","    SELECTED_FOLDS = [0]\n","    DROP_REMAINDER = True # Drop remainder - dropping last batch if size < batch size\n","    EPOCHS = 50\n","    \n","    # Training monitoring\n","    PLOT_HISTORY = True\n","    \n","def seeding(SEED):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    tf.random.set_seed(SEED)\n","    print('seeding done!!!')\n","    \n","seeding(CFG.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["## Login to WANDB to log trainings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:12:25.336389Z","iopub.status.busy":"2024-05-19T14:12:25.335845Z","iopub.status.idle":"2024-05-19T14:12:29.020835Z","shell.execute_reply":"2024-05-19T14:12:29.019809Z","shell.execute_reply.started":"2024-05-19T14:12:25.336362Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:43:17.814766Z","iopub.status.busy":"2024-05-19T16:43:17.814031Z","iopub.status.idle":"2024-05-19T16:43:17.820107Z","shell.execute_reply":"2024-05-19T16:43:17.819108Z","shell.execute_reply.started":"2024-05-19T16:43:17.814730Z"},"trusted":true},"outputs":[],"source":["wandb_config={\n","    \"architecture\": CFG.NETWORK_NAME,\n","    \"input_shape\": CFG.CNN_INPUT_SHAPE,\n","    \"epochs\": CFG.EPOCHS,\n","    \"batch_size\": CFG.BATCH_SIZE,\n","    \"seed\": CFG.SEED,\n","    \"use_small_sample\": False, \n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:43:18.987164Z","iopub.status.busy":"2024-05-19T16:43:18.986793Z","iopub.status.idle":"2024-05-19T16:43:50.519689Z","shell.execute_reply":"2024-05-19T16:43:50.518649Z","shell.execute_reply.started":"2024-05-19T16:43:18.987137Z"},"trusted":true},"outputs":[],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"one-shot-flowers\",\n","\n","    # track hyperparameters and run metadata with wandb.config\n","    config=wandb_config\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Load datasets"]},{"cell_type":"markdown","metadata":{},"source":["### Loading whole dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Extract all images from source dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:00.265380Z","iopub.status.busy":"2024-05-19T14:13:00.264347Z","iopub.status.idle":"2024-05-19T14:13:08.209777Z","shell.execute_reply":"2024-05-19T14:13:08.208844Z","shell.execute_reply.started":"2024-05-19T14:13:00.265344Z"},"trusted":true},"outputs":[],"source":["import tarfile \n","\n","if not os.path.isdir('/kaggle/working/flowers-102-source-extracted'):\n","    with tarfile.open('/kaggle/input/oxford-flowers-102-source/102flowers.tgz') as f: \n","        f.extractall('/kaggle/working/flowers-102-source-extracted') "]},{"cell_type":"markdown","metadata":{},"source":["#### Load labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:08.211354Z","iopub.status.busy":"2024-05-19T14:13:08.210996Z","iopub.status.idle":"2024-05-19T14:13:08.531715Z","shell.execute_reply":"2024-05-19T14:13:08.530722Z","shell.execute_reply.started":"2024-05-19T14:13:08.211323Z"},"trusted":true},"outputs":[],"source":["from scipy.io import loadmat\n","\n","labels_mine = loadmat('/kaggle/input/oxford-flowers-102-source/imagelabels.mat')[\"labels\"][0]\n","\n","labels_mine"]},{"cell_type":"markdown","metadata":{},"source":["#### Load whole dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:08.536488Z","iopub.status.busy":"2024-05-19T14:13:08.536178Z","iopub.status.idle":"2024-05-19T14:13:14.700629Z","shell.execute_reply":"2024-05-19T14:13:14.699556Z","shell.execute_reply.started":"2024-05-19T14:13:08.536456Z"},"trusted":true},"outputs":[],"source":["DIR_PATH = '/kaggle/working/flowers-102-source-extracted/jpg'\n","\n","df_all = pd.DataFrame(columns=[\"filepath\", \"target\", \"targetName\"])\n","idx = 0\n","for image, label in zip(sorted(os.listdir(DIR_PATH)), labels_mine):\n","    new_row = pd.DataFrame({\"filepath\": os.path.join(DIR_PATH, image),\n","                            \"target\": label,\n","                           \"targetName\": CFG.CATEGORIES[label]}, \n","                               index=[idx])\n","    \n","    df_all = pd.concat([df_all, new_row], ignore_index=True)\n","    \n","    idx += 1\n","    \n","df_all[\"target\"] = df_all[\"target\"].astype(int)\n","print(df_all.head())\n","print(df_all.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Train-Test Split"]},{"cell_type":"markdown","metadata":{},"source":["#### Divide into Training and Test split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:14.702792Z","iopub.status.busy":"2024-05-19T14:13:14.702232Z","iopub.status.idle":"2024-05-19T14:13:14.852317Z","shell.execute_reply":"2024-05-19T14:13:14.851385Z","shell.execute_reply.started":"2024-05-19T14:13:14.702757Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming `df` is your DataFrame\n","# Splitting the DataFrame into train and test sets, stratified by the 'target' column\n","train_df, test_df = train_test_split(\n","    df_all, \n","    test_size=0.2,  # 20% for testing, 80% for training\n","    stratify=df_all['target'],  # Stratify by the 'target' column to maintain class distribution\n","    random_state=CFG.SEED  # For reproducibility\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Divide Training set into Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:16:55.601019Z","iopub.status.busy":"2024-05-19T14:16:55.600159Z","iopub.status.idle":"2024-05-19T14:16:55.629926Z","shell.execute_reply":"2024-05-19T14:16:55.628744Z","shell.execute_reply.started":"2024-05-19T14:16:55.600984Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","\n","skf = StratifiedKFold(n_splits=CFG.NUM_SPLITS, shuffle=True, random_state=CFG.SEED)\n","\n","df = train_df.reset_index(drop=True)\n","\n","df[\"fold\"] = -1\n","for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n","    df.loc[val_idx, 'fold'] = fold\n","    \n","# Apply the conversion logic\n","df['split'] = df['fold'].apply(lambda x: 'val' if x == 0 else 'train')\n","\n","# Drop the original 'fold' column and rename it to 'split'\n","df = df.drop('fold', axis=1)\n","\n","# Display or save the updated DataFrame\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:17:05.155480Z","iopub.status.busy":"2024-05-19T14:17:05.155071Z","iopub.status.idle":"2024-05-19T14:17:05.245117Z","shell.execute_reply":"2024-05-19T14:17:05.243515Z","shell.execute_reply.started":"2024-05-19T14:17:05.155452Z"},"trusted":true},"outputs":[],"source":["# Sample 10 items from each target category\n","df = df.groupby('target').apply(lambda x: x.sample(n=10, replace=True if len(x) < 10 else False, random_state=CFG.SEED)).reset_index(drop=True)\n","\n","df"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize 10 random images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:14.973064Z","iopub.status.busy":"2024-05-19T14:13:14.972634Z","iopub.status.idle":"2024-05-19T14:13:14.980290Z","shell.execute_reply":"2024-05-19T14:13:14.979372Z","shell.execute_reply.started":"2024-05-19T14:13:14.973028Z"},"trusted":true},"outputs":[],"source":["def display_10_images(dataset):\n","\n","    images = dataset.sample(10, random_state=CFG.SEED)\n","\n","    plt.figure(figsize=(15, 6))  # Increase figure size for better visibility\n","    i = 0\n","    for _, image in images.iterrows():\n","        plt.subplot(2, 5, i + 1)  # 2 rows, 5 columns, ith+1 subplot\n","        plt.imshow(Image.open(image.filepath))\n","        plt.title(f'Class: {image.targetName}')\n","        plt.axis('off')\n","        i += 1\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:14.981734Z","iopub.status.busy":"2024-05-19T14:13:14.981429Z","iopub.status.idle":"2024-05-19T14:13:16.245717Z","shell.execute_reply":"2024-05-19T14:13:16.242078Z","shell.execute_reply.started":"2024-05-19T14:13:14.981710Z"},"trusted":true},"outputs":[],"source":["display_10_images(df)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["### Traditional Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:16.247408Z","iopub.status.busy":"2024-05-19T14:13:16.247046Z","iopub.status.idle":"2024-05-19T14:13:29.783877Z","shell.execute_reply":"2024-05-19T14:13:29.782766Z","shell.execute_reply.started":"2024-05-19T14:13:16.247377Z"},"trusted":true},"outputs":[],"source":["!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:29.786218Z","iopub.status.busy":"2024-05-19T14:13:29.785815Z","iopub.status.idle":"2024-05-19T14:13:29.868010Z","shell.execute_reply":"2024-05-19T14:13:29.867003Z","shell.execute_reply.started":"2024-05-19T14:13:29.786176Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","def random_rotate_image(image):\n","    # Generate a random angle for rotation. The angle is in radians.\n","    # Here, we rotate between -45 and 45 degrees, converted to radians.\n","    angle_rad = tf.random.uniform(shape=[], minval=-0.25*np.pi, maxval=0.25*np.pi)\n","    # Rotate the image\n","    rotated_image = tfa.image.rotate(image, angles=angle_rad, interpolation='NEAREST', fill_mode='reflect')\n","    return rotated_image\n","\n","# Generats random float\n","def random_float(shape=[], minval=0.0, maxval=1.0):\n","    rnd = tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n","    return rnd\n","\n","def traditional_image_aug(image):\n","    # Flipping left right\n","    image = tf.image.random_flip_left_right(image)\n","    \n","    # Brightness\n","    image = tf.image.random_brightness(image, max_delta=0.23)\n","    \n","    # Contrast\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    \n","    # Gaussian Filter\n","    image = tfa.image.gaussian_filter2d(image, filter_shape=(3, 3), sigma=1.0)\n","    \n","    # Rotate max 45 degrees\n","    image = random_rotate_image(image)\n","    \n","    # Add gaussian noise\n","    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.03, dtype=tf.float32)\n","    image = image + noise \n","    \n","    # Random Cropping \n","    max_ratio = random_float(minval=0.8, maxval=1.0)\n","    new_height = int(CFG.CNN_INPUT_HEIGHT * max_ratio)\n","    new_width = int(CFG.CNN_INPUT_WIDTH * max_ratio)\n","    image = tf.image.random_crop(image, size=[new_height, new_width, CFG.CNN_INPUT_CHANNELS])\n","    image = tf.image.resize(image, [CFG.CNN_INPUT_HEIGHT, CFG.CNN_INPUT_WIDTH])\n","    return image\n","\n","def traditional_image_augmenter(with_labels=True):\n","    def augment(image):\n","        if random_float() <= CFG.TRADITIONAL_AUG_PROB:\n","            image = traditional_image_aug(image)\n","        return image\n","\n","    def augment_with_labels(image, label):\n","        return augment(image), label\n","\n","    return augment_with_labels if with_labels else augment"]},{"cell_type":"markdown","metadata":{},"source":["### Advanced Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["#### MixUp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:29.869834Z","iopub.status.busy":"2024-05-19T14:13:29.869485Z","iopub.status.idle":"2024-05-19T14:13:29.878321Z","shell.execute_reply":"2024-05-19T14:13:29.877329Z","shell.execute_reply.started":"2024-05-19T14:13:29.869801Z"},"trusted":true},"outputs":[],"source":["def mixup_image_aug(images, labels, alpha=CFG.MIXUP_ALPHA):\n","    \n","    if random_float() > CFG.MIXUP_PROB:\n","        return images, labels\n","    \n","    image_shape = tf.shape(images)\n","    label_shape = tf.shape(labels)\n","\n","    beta = tfp.distributions.Beta(alpha, alpha) \n","    lam = beta.sample(1)[0]\n","#     beta_distribution = beta(alpha, alpha)\n","#     lam = beta_distribution.rvs(size=1)[0]\n","\n","    images = lam * images + (1 - lam) * tf.roll(images, shift=1, axis=0)\n","    labels = lam * labels + (1 - lam) * tf.roll(labels, shift=1, axis=0)\n","\n","    images = tf.reshape(images, image_shape)\n","    labels = tf.reshape(labels, label_shape)\n","    \n","    return images, labels"]},{"cell_type":"markdown","metadata":{},"source":["#### CutMix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:29.881416Z","iopub.status.busy":"2024-05-19T14:13:29.880707Z","iopub.status.idle":"2024-05-19T14:13:29.901814Z","shell.execute_reply":"2024-05-19T14:13:29.900927Z","shell.execute_reply.started":"2024-05-19T14:13:29.881384Z"},"trusted":true},"outputs":[],"source":["\n","import tensorflow as tf\n","\n","\n","\n","def create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size):\n","    # Create a grid of coordinates (height x width)\n","    x_coords = tf.range(width)\n","    y_coords = tf.range(height)\n","    Y, X = tf.meshgrid(y_coords, x_coords)\n","\n","    # Reshape the bounding box coordinates to make them broadcastable over the batch size\n","    bbx1 = tf.reshape(bbx1, [batch_size, 1, 1])\n","    bby1 = tf.reshape(bby1, [batch_size, 1, 1])\n","    bbx2 = tf.reshape(bbx2, [batch_size, 1, 1])\n","    bby2 = tf.reshape(bby2, [batch_size, 1, 1])\n","\n","    # Create the mask by comparing the coordinates\n","    mask = (X >= bbx1) & (X < bbx2) & (Y >= bby1) & (Y < bby2)\n","    mask = tf.cast(mask, tf.float32)  # Convert the mask to float32\n","    \n","    # Calculate ratio \n","    patch_area = tf.reduce_sum(mask, axis=[1, 2])  # Sum over height, width, and channels dimensions\n","    total_area = height * width\n","    ratio = patch_area / tf.cast(total_area, tf.float32)\n","    ratio = tf.expand_dims(ratio, -1)\n","    ratio = tf.tile(ratio, [1, 102])\n","    # Add the channel dimension\n","    mask = tf.expand_dims(mask, -1)\n","    # Tile the mask across the channel dimension\n","    mask = tf.tile(mask, [1, 1, 1, channels])\n","    \n","    \n","    return mask, ratio\n","\n","\n","def cutmix(images, labels, probability=0.5, alpha=1.0):\n","    # Only apply CutMix with the given probability\n","    if random_float() > probability:\n","        return images, labels\n","\n","    # Assume images is a 4D tensor of shape [batch_size, height, width, channels]\n","    shape = tf.shape(images)\n","    \n","    batch_size = shape[0]\n","    height = shape[1]\n","    width = shape[2]\n","    channels = shape[3]\n","    \n","    # Sample lambda and calculate patch dimensions\n","    beta = tfp.distributions.Beta(alpha, alpha)\n","    lambda_val = beta.sample(1)\n","#     beta_distribution = beta(alpha, alpha)\n","#     lambda_val = beta_distribution.rvs(size=1)[0]\n","\n","\n","    cut_rat = tf.sqrt(1. - lambda_val)\n","    \n","    cut_w = tf.cast(width, tf.float32) * cut_rat\n","    cut_w = tf.cast(cut_w, tf.int32)  # Now, cut_w is an int32 tensor.\n","    \n","    cut_h = tf.cast(height, tf.float32) * cut_rat\n","    cut_h = tf.cast(cut_h, tf.int32)  # Now, cut_h is an int32 tensor.\n","    \n","    # Uniformly sample the center of the patch\n","    cx = tf.random.uniform([batch_size], minval=0, maxval=width, dtype=tf.int32)\n","    cy = tf.random.uniform([batch_size], minval=0, maxval=height, dtype=tf.int32)\n","    \n","    # Calculate the patch coordinates\n","    bbx1 = tf.clip_by_value(cx - cut_w // 2, 0, width)\n","    bby1 = tf.clip_by_value(cy - cut_h // 2, 0, height)\n","    bbx2 = tf.clip_by_value(cx + cut_w // 2, 0, width)\n","    bby2 = tf.clip_by_value(cy + cut_h // 2, 0, height)\n","    \n","#     # Create mask\n","    mask, ratio = create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size)\n","    indices = tf.random.shuffle(tf.range(batch_size))\n","    mixed_images = images * mask + tf.gather(images, indices) * (1 - mask)\n","\n","    # Mix the labels\n","    mixed_labels = labels * ratio + tf.gather(labels, indices) * (1 - ratio)\n","#     mixed_labels = labels\n","    \n","    return mixed_images, mixed_labels\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"markdown","metadata":{},"source":["### Define metrics, loss, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:29.903674Z","iopub.status.busy":"2024-05-19T14:13:29.903324Z","iopub.status.idle":"2024-05-19T14:13:29.915510Z","shell.execute_reply":"2024-05-19T14:13:29.914476Z","shell.execute_reply.started":"2024-05-19T14:13:29.903643Z"},"trusted":true},"outputs":[],"source":["import sklearn.metrics\n","\n","def get_metrics():\n","    auc = tf.keras.metrics.AUC(curve='PR', name='auc', multi_label=False) # auc on prcision-recall curve\n","    acc = tf.keras.metrics.CategoricalAccuracy(name='acc')\n","    return [acc, auc]\n","\n","def padded_cmap(y_true, y_pred, padding_factor=5):\n","    num_classes = y_true.shape[1]\n","    pad_rows = np.array([[1]*num_classes]*padding_factor)\n","    y_true = np.concatenate([y_true, pad_rows])\n","    y_pred = np.concatenate([y_pred, pad_rows])\n","    score = sklearn.metrics.average_precision_score(y_true, y_pred, average='macro',)\n","    return score\n","\n","def get_loss():\n","    if CFG.loss==\"CCE\":\n","        loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=CFG.label_smoothing)\n","    else:\n","        raise ValueError(\"Loss not found\")\n","    return loss\n","    \n","def get_optimizer():\n","    if CFG.optimizer == \"Adam\":\n","        opt = tf.keras.optimizers.Adam(learning_rate=CFG.lr)\n","    else:\n","        raise ValueError(\"Optmizer not found\")\n","    return opt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:13:29.917195Z","iopub.status.busy":"2024-05-19T14:13:29.916616Z","iopub.status.idle":"2024-05-19T14:13:29.931428Z","shell.execute_reply":"2024-05-19T14:13:29.930371Z","shell.execute_reply.started":"2024-05-19T14:13:29.917163Z"},"trusted":true},"outputs":[],"source":["# import efficientnet.tfkeras as efn\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","def build_model_resnet(CFG, compile_model=True):\n","    \"\"\"\n","    Builds and returns a model based on the specified configuration.\n","    \"\"\"\n","  \n","    DIM = (None, None)\n","\n","    # Base model - Resnet50\n","    base = tf.keras.applications.ResNet50(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","\n","    # Input layer \n","    inp = tf.keras.layers.Input(shape=(*DIM, 3))\n","\n","    out = inp\n","    # Input -> base \n","#     out = base(inp)\n","    for layer in base.layers:\n","        print(layer)\n","        out = layer(out)\n","\n","    # GAP Layer\n","    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n","\n","    # Final dense layer for classification\n","    out = tf.keras.layers.Dense(len(CFG.CATEGORIES), activation='softmax')(out)\n","\n","    # Create the TensorFlow model \n","    model = tf.keras.Model(inputs=inp, outputs=out)\n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:15:45.274126Z","iopub.status.busy":"2024-05-19T14:15:45.273237Z","iopub.status.idle":"2024-05-19T14:15:45.284633Z","shell.execute_reply":"2024-05-19T14:15:45.283608Z","shell.execute_reply.started":"2024-05-19T14:15:45.274092Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","\n","def build_flattened_model_resnet(CFG, compile_model=True):\n","\n","    DIM = (None, None)\n","    # Load the base ResNet50 model without the top classification layers\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*DIM, 3))\n","\n","    # Make sure all layers are set to trainable for fine-tuning\n","    for layer in base_model.layers:\n","        layer.trainable = True\n","\n","    # Add custom layers on top of ResNet50\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(len(CFG.CATEGORIES), activation='softmax', name='output_layer')(x)  # Change the number of units and activation based on your task\n","\n","    # Create the complete model\n","    model = Model(inputs=base_model.input, outputs=x)\n","\n","    # Print the model summary\n","    \n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Train model using cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:18:01.620728Z","iopub.status.busy":"2024-05-19T14:18:01.619999Z","iopub.status.idle":"2024-05-19T14:18:01.633624Z","shell.execute_reply":"2024-05-19T14:18:01.632659Z","shell.execute_reply.started":"2024-05-19T14:18:01.620697Z"},"trusted":true},"outputs":[],"source":["def image_decoder(path, label=None, with_labels=True):\n","    def image_loader(path):\n","        if not os.path.exists(path):\n","            pass\n","        image = tf.io.read_file(path)\n","        image = tf.image.decode_jpeg(image, channels=3)\n","        image = tf.cast(image, tf.float32)\n","        image = tf.image.resize(image, CFG.CNN_INPUT_SIZE)\n","        image = image / 255.0\n","        \n","        image.set_shape([CFG.CNN_INPUT_HEIGHT, CFG.CNN_INPUT_WIDTH, CFG.CNN_INPUT_CHANNELS])\n","        \n","        return image\n","    \n","    def target_loader(target):\n","#         target = tf.reshape(target, [1])\n","        target = tf.cast(tf.one_hot(target, depth=len(CFG.CATEGORIES)), dtype=tf.float32)\n","        return target #tf.reshape(target, [len(CFG.CATEGORIES)])\n","\n","    def decode(path):\n","        image = image_loader(path)\n","        return image\n","\n","    def decode_with_labels(path, label):\n","        label = target_loader(label)\n","        return decode(path), label\n","    if type(path) == str:\n","        return decode_with_labels(path, label) if with_labels else decode(path)\n","    return decode_with_labels(path.numpy(), label.numpy()) if with_labels else decode(path.numpy())\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:15:50.799643Z","iopub.status.busy":"2024-05-19T14:15:50.798561Z","iopub.status.idle":"2024-05-19T14:15:50.814298Z","shell.execute_reply":"2024-05-19T14:15:50.813158Z","shell.execute_reply.started":"2024-05-19T14:15:50.799596Z"},"trusted":true},"outputs":[],"source":["def build_dataset(paths, labels=None, batch_size=CFG.BATCH_SIZE, target_size=CFG.CNN_INPUT_SIZE,\n","                  image_decoder_fn=None, traditional_augment_fn=None,\n","                  spec_decode_fn=None, mixup_image_augment_fn=None,\n","                  cache=True, cache_dir=\"\",drop_remainder=False,\n","                  augment=True, repeat=True, shuffle=100):\n","    \"\"\"\n","    Creates a TensorFlow dataset from the given paths and labels.\n","\n","    Args:\n","        paths (list): A list of file paths to the audio files.\n","        labels (list): A list of corresponding labels for the audio files.\n","        batch_size (int): Batch size for the created dataset.\n","        target_size (list): A list of target image size for the spectrograms.\n","        audio_decode_fn (function): A function to decode the audio file.\n","        audio_augment_fn (function): A function to augment the audio file.\n","        spec_decode_fn (function): A function to decode the spectrogram.\n","        spec_augment_fn (function): A function to augment the spectrogram.\n","        cache (bool): Whether to cache the dataset or not.\n","        cache_dir (str): Directory path to cache the dataset.\n","        drop_remainder (bool): Whether to drop the last batch if it is smaller than batch_size.\n","        augment (bool): Whether to augment the dataset or not.\n","        repeat (bool): Whether to repeat the dataset or not.\n","        shuffle (int): Number of elements from the dataset to buffer for shuffling.\n","\n","    Returns:\n","        ds (tf.data.Dataset): A TensorFlow dataset.\n","    \"\"\"\n","\n","#     # Create cache directory if cache is enabled\n","#     if cache_dir != \"\" and cache is True:\n","#         os.makedirs(cache_dir, exist_ok=True)\n","\n","    # Set default functions if not provided\n","    if image_decoder_fn is None:\n","        image_decoder_fn = image_decoder\n","\n","    if traditional_augment_fn is None:\n","        traditional_augment_fn = traditional_image_augmenter(\n","            labels is not None)\n","        \n","#     if mixup_image_augment_fn is None:\n","#         mixup_image_augment_fn = mixup_image_aug(\n","#             labels is not None)\n","#     if spec_decode_fn is None:\n","#         spec_decode_fn = spec_decoder(\n","#             labels is not None, dim=CFG.img_size, CFG=CFG)\n","\n","#     if spec_augment_fn is None:\n","#         spec_augment_fn = spec_augmenter(\n","#             labels is not None, dim=CFG.img_size, CFG=CFG)\n","\n","    AUTO = tf.data.experimental.AUTOTUNE\n","\n","\n","    slices = paths if labels is None else (paths, labels)\n","    ds = tf.data.Dataset.from_tensor_slices(slices)\n","\n","    if labels is None:\n","        ds = ds.map(lambda x: tf.py_function(image_decoder_fn, [x], [tf.float32]), num_parallel_calls=AUTO)\n","    else:\n","        ds = ds.map(lambda x, y: tf.py_function(image_decoder_fn, [x, y], [tf.float32, tf.float32]), num_parallel_calls=AUTO)\n","    \n","\n","#     ds = ds.cache(cache_dir) if cache else ds\n","\n","    ds = ds.repeat() if repeat else ds\n","\n","#     opt = tf.data.Options()\n","\n","    if shuffle:\n","        ds = ds.shuffle(shuffle, seed=CFG.SEED)\n","#         opt.experimental_deterministic = False\n","\n","#     if CFG.device=='GPU':\n","#         opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","\n","    ds = ds.map(traditional_augment_fn, num_parallel_calls=AUTO) if augment else ds\n","\n","    ds = ds.batch(batch_size, drop_remainder=CFG.DROP_REMAINDER)\n","\n","    ds = ds.map(mixup_image_aug, num_parallel_calls=AUTO) if augment else ds # if (augment and labels is not None) else ds\n","    \n","    ds = ds.map(lambda images, labels: cutmix(images, labels, probability=CFG.CUTMIX_PROB, alpha=CFG.CUTMIX_ALPHA), num_parallel_calls=AUTO) if augment else ds\n","#     if CFG.MIXUP_PROB and augment and labels is not None:\n","#         ds = ds.map(mixup_image_augmenter(alpha=CFG.MIXUP_ALPHA,prob=CFG.MIXUP_PROB),num_parallel_calls=AUTO)\n","\n","#     if CFG.cutmix_prob and augment and labels is not None:\n","#         ds = ds.map(CutMix(alpha=CFG.cutmix_alpha,prob=CFG.cutmix_prob),num_parallel_calls=AUTO)\n","\n","    ds = ds.prefetch(AUTO)\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:15:54.529122Z","iopub.status.busy":"2024-05-19T14:15:54.528762Z","iopub.status.idle":"2024-05-19T14:15:54.546791Z","shell.execute_reply":"2024-05-19T14:15:54.545301Z","shell.execute_reply.started":"2024-05-19T14:15:54.529095Z"},"trusted":true},"outputs":[],"source":["def plot_history(history):\n","    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n","    epochs = len(history.history['auc'])\n","    plt.figure(figsize=(15,5))\n","    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n","    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n","    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n","    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n","    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n","    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n","    plt.ylabel('Loss',size=14)\n","    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n","    plt.legend(loc=3)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## WANDB Logging"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:15:56.256193Z","iopub.status.busy":"2024-05-19T14:15:56.255576Z","iopub.status.idle":"2024-05-19T14:15:57.268908Z","shell.execute_reply":"2024-05-19T14:15:57.267726Z","shell.execute_reply.started":"2024-05-19T14:15:56.256161Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:15:59.006252Z","iopub.status.busy":"2024-05-19T14:15:59.005840Z","iopub.status.idle":"2024-05-19T14:15:59.038977Z","shell.execute_reply":"2024-05-19T14:15:59.037945Z","shell.execute_reply.started":"2024-05-19T14:15:59.006214Z"},"trusted":true},"outputs":[],"source":["from wandb.keras import WandbCallback\n","\n","\n","def train_val_test_fit(model, df, CFG, model_name=\"Model\"):\n","    # Split dataset with cv filter\n","    train_df = df.query(\"split == 'train'\").reset_index(drop=True) \n","    valid_df = df.query(\"split=='val'\").reset_index(drop=True) \n","\n","    # Get file paths and labels\n","    train_paths = train_df.filepath.values; train_labels = train_df.target.values\n","    valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n","\n","\n","    # Shuffle the file paths and labels\n","    index = np.arange(len(train_paths))\n","    np.random.shuffle(index)\n","    train_paths  = train_paths[index]\n","    train_labels = train_labels[index]\n","\n","    # Compute the number of training and validation samples\n","    num_train = len(train_paths); num_valid = len(valid_paths)\n","        \n","    # # Build the training and validation datasets\n","    cache=True\n","    train_ds = build_dataset(train_paths, train_labels, \n","                              batch_size=CFG.BATCH_SIZE, cache=cache, shuffle=True,\n","                            augment=CFG.AUGMENT, drop_remainder=CFG.DROP_REMAINDER)\n","    valid_ds = build_dataset(valid_paths, valid_labels,\n","                              batch_size=CFG.BATCH_SIZE, cache=cache, shuffle=False,\n","                              augment=False, repeat=False, drop_remainder=CFG.DROP_REMAINDER)\n","\n","\n","    # # Print information about the training\n","    print('#### Image Size: (%i, %i) | Model: %s | Batch Size: %i '%\n","          (*CFG.CNN_INPUT_SIZE, model_name, CFG.BATCH_SIZE))\n","    print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n","\n","    # # Callbacks\n","    sv = tf.keras.callbacks.ModelCheckpoint(\n","        'training_save.keras', monitor='val_acc', verbose=0, save_best_only=True,\n","        save_weights_only=False, mode='max', save_freq='epoch')\n","    callbacks = [sv,  \n","                 WandbCallback(generator=valid_ds)] # get_lr_callback(CFG.batch_size)\n","\n","    # # Training\n","    print('# Training')\n","    history = model.fit(\n","        train_ds, \n","        epochs=CFG.EPOCHS, \n","        callbacks=callbacks, \n","        steps_per_epoch=len(train_paths)//CFG.BATCH_SIZE,\n","        validation_data=valid_ds, \n","        # verbose=CFG.verbose,\n","    )\n","    \n","    model = tf.keras.models.load_model('/kaggle/working/training_save.keras')\n","    \n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:43:50.521771Z","iopub.status.busy":"2024-05-19T16:43:50.521454Z","iopub.status.idle":"2024-05-19T17:05:34.436331Z","shell.execute_reply":"2024-05-19T17:05:34.435134Z","shell.execute_reply.started":"2024-05-19T16:43:50.521742Z"},"trusted":true},"outputs":[],"source":[" # # Clear the session, build and train the model\n","K.clear_session()\n","# model = build_model_resnet(CFG) \n","model = build_flattened_model_resnet(CFG)\n","model, history = train_val_test_fit(model, df, CFG, model_name=\"EfficientNet\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Predict on Test Set"]},{"cell_type":"markdown","metadata":{},"source":["#### Prediction utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T17:08:39.964359Z","iopub.status.busy":"2024-05-19T17:08:39.963697Z","iopub.status.idle":"2024-05-19T17:08:39.972532Z","shell.execute_reply":"2024-05-19T17:08:39.971419Z","shell.execute_reply.started":"2024-05-19T17:08:39.964323Z"},"trusted":true},"outputs":[],"source":["def predict_classes(model, paths):\n","    fake_labels = np.zeros(test_paths.shape, dtype=int)\n","    ds = build_dataset(paths, fake_labels,\n","                    batch_size=1, cache=False, shuffle=False,\n","                    augment=False, repeat=False, drop_remainder=False)\n","\n","    preds = model.predict(ds)\n","    pred_labels = np.argmax(preds, axis=1)\n","\n","    return pred_labels, preds"]},{"cell_type":"markdown","metadata":{},"source":["#### Predict and calculate score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:57:48.363092Z","iopub.status.busy":"2024-05-19T14:57:48.362152Z","iopub.status.idle":"2024-05-19T14:58:06.782853Z","shell.execute_reply":"2024-05-19T14:58:06.780371Z","shell.execute_reply.started":"2024-05-19T14:57:48.363043Z"},"trusted":true},"outputs":[],"source":["test_paths = test_df.filepath.values; test_labels = test_df.target.values\n","\n","preds, probs = predict_classes(model, test_paths)\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","accuracy = accuracy_score(test_labels, preds)\n","precision = precision_score(test_labels, preds, average='weighted') \n","recall = recall_score(test_labels, preds, average='weighted') \n","f1 = f1_score(test_labels, preds, average='weighted')  \n","\n","\n","wandb.log({\n","    \"Test Accuracy\": accuracy,\n","    \"Test Precision\": precision,\n","    \"Test Recall\": recall,\n","    \"Test F1 Score\": f1\n","})\n","\n","print(f\"Accuracy: {accuracy} Precision: {precision} Recall: {recall} F1: {f1}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### WANDB: Log confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:58:06.786164Z","iopub.status.busy":"2024-05-19T14:58:06.785699Z","iopub.status.idle":"2024-05-19T14:58:06.795615Z","shell.execute_reply":"2024-05-19T14:58:06.794399Z","shell.execute_reply.started":"2024-05-19T14:58:06.786120Z"},"trusted":true},"outputs":[],"source":["adjusted_test_labels = [label - 1 for label in test_labels]\n","adjusted_preds = [pred - 1 for pred in preds]\n","adjusted_categories = {k-1: v for k, v in CFG.CATEGORIES.items()}\n","\n","# wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n","#                         y_true=adjusted_test_labels, preds=adjusted_preds,\n","#                         class_names=adjusted_categories)})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:58:06.797255Z","iopub.status.busy":"2024-05-19T14:58:06.796893Z","iopub.status.idle":"2024-05-19T14:58:07.977663Z","shell.execute_reply":"2024-05-19T14:58:07.976271Z","shell.execute_reply.started":"2024-05-19T14:58:06.797226Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def create_top_10_confusion_matrix(true_labels, preds, class_names):\n","    # Assuming adjusted_labels and adjusted_preds are properly defined\n","    num_classes = len(class_names)  # Total number of classes\n","    class_labels = range(num_classes)  # Zero-based class labels\n","    \n","    adjusted_labels = test_labels - 1\n","    adjusted_preds = preds - 1\n","    adjusted_categories = {k-1: v for k, v in CFG.CATEGORIES.items()}\n","\n","    # Create the full confusion matrix with adjusted labels\n","    full_cm = confusion_matrix(adjusted_labels, adjusted_preds, labels=class_labels)\n","\n","    # Calculate misclassification counts (not including correct classifications)\n","    misclassification_counts = full_cm.sum(axis=1) - np.diag(full_cm)\n","    total_true_counts = np.bincount(adjusted_labels, minlength=num_classes)\n","    misclassification_rates = misclassification_counts / total_true_counts\n","\n","    # Identify top 10 most frequently misclassified classes\n","    top_10_classes = np.argsort(-misclassification_rates)[:10]\n","\n","    # Create reduced confusion matrix for top 10 classes\n","    top_10_cm = full_cm[top_10_classes, :][:, top_10_classes]\n","\n","    # Calculate \"Other\" row and column properly\n","    total_predictions_sum = full_cm.sum(axis=0)[top_10_classes]  # All predictions sum\n","    total_true_sum = full_cm.sum(axis=1)[top_10_classes]  # All true labels sum\n","    other_row = total_predictions_sum - top_10_cm.sum(axis=0)\n","    other_column = total_true_sum - top_10_cm.sum(axis=1)\n","\n","    # Append the \"Other\" value\n","    other_value = np.nan\n","    \n","    # Forming the 11x11 confusion matrix\n","    final_cm = np.vstack([\n","        np.hstack([top_10_cm, other_column.reshape(-1, 1)]),\n","        np.hstack([other_row, other_value])\n","    ])\n","\n","    # Labels for plotting (adjust labels back to 1-102 for readability)\n","    labels = [f'{CFG.CATEGORIES[i+1]}' for i in top_10_classes] + ['Other']\n","\n","    # Plotting\n","    plt.figure(figsize=(12, 10))\n","    sns.heatmap(final_cm, annot=True, cmap=\"Blues\", fmt=\".0f\", xticklabels=labels, yticklabels=labels)\n","    plt.title('Confusion Matrix for Top 10 Most Frequently Misclassified Categories')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.savefig(\"confusion_matrix.png\")\n","    plt.show()\n","    \n","    return final_cm\n","\n","top_10_cm = create_top_10_confusion_matrix(test_labels, preds, CFG.CATEGORIES)\n","wandb.log({\"Top 10 Confusion Matrix\": wandb.Image(\"confusion_matrix.png\")})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:58:07.981259Z","iopub.status.busy":"2024-05-19T14:58:07.980183Z","iopub.status.idle":"2024-05-19T14:58:07.990672Z","shell.execute_reply":"2024-05-19T14:58:07.989548Z","shell.execute_reply.started":"2024-05-19T14:58:07.981219Z"},"trusted":true},"outputs":[],"source":["def plot_batch(batch, row=3, col=3):\n","    \"\"\"Plot one batch data\"\"\"\n","    if isinstance(batch, tuple) or isinstance(batch, list):\n","        imgs, tars = batch\n","    else:\n","        imgs = batch\n","        tars = None\n","    plt.figure(figsize=(col*2, row*2))\n","    \n","    for idx in range(row*col):\n","        ax = plt.subplot(row, col, idx+1)\n","        ax.imshow(imgs[idx])\n","        plt.axis('off')\n","\n","        if tars is not None:\n","            label = tars[idx].numpy().argmax()\n","            if label == 0:\n","                label = 102\n","            name = CFG.CATEGORIES[label]\n","            plt.title(name)\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:48:13.880636Z","iopub.status.busy":"2024-05-03T19:48:13.880201Z","iopub.status.idle":"2024-05-03T19:48:16.03421Z","shell.execute_reply":"2024-05-03T19:48:16.03317Z","shell.execute_reply.started":"2024-05-03T19:48:13.880601Z"},"trusted":true},"outputs":[],"source":["DESIRED_BATCH = 3\n","ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=False, cache=False, shuffle=None)\n","ds = ds.take(100)\n","ds_iter = iter(ds)\n","\n","for idx, (imgs, labels) in enumerate(ds_iter):\n","    if idx == DESIRED_BATCH:\n","        plot_batch((imgs, labels), 2, 5)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:57:36.073402Z","iopub.status.busy":"2024-05-03T19:57:36.072543Z","iopub.status.idle":"2024-05-03T19:57:41.287548Z","shell.execute_reply":"2024-05-03T19:57:41.28051Z","shell.execute_reply.started":"2024-05-03T19:57:36.073366Z"},"trusted":true},"outputs":[],"source":["ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=True, cache=False, shuffle=None)\n","ds = ds.take(100)\n","ds_iter = iter(ds)\n","\n","for idx, (imgs, labels) in enumerate(ds_iter):\n","    if idx == DESIRED_BATCH:\n","        print(labels[9])\n","        plot_batch((imgs, labels), 2, 5)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T18:02:37.964687Z","iopub.status.busy":"2024-05-19T18:02:37.964254Z","iopub.status.idle":"2024-05-19T18:02:45.822582Z","shell.execute_reply":"2024-05-19T18:02:45.821650Z","shell.execute_reply.started":"2024-05-19T18:02:37.964650Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Load model from wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-04T17:45:36.151038Z","iopub.status.busy":"2024-05-04T17:45:36.150104Z","iopub.status.idle":"2024-05-04T17:45:40.569759Z","shell.execute_reply":"2024-05-04T17:45:40.568803Z","shell.execute_reply.started":"2024-05-04T17:45:36.151000Z"},"trusted":true},"outputs":[],"source":["import wandb\n","\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-04T17:46:06.481001Z","iopub.status.busy":"2024-05-04T17:46:06.480025Z","iopub.status.idle":"2024-05-04T17:46:08.597525Z","shell.execute_reply":"2024-05-04T17:46:08.596756Z","shell.execute_reply.started":"2024-05-04T17:46:06.480964Z"},"trusted":true},"outputs":[],"source":["wandb.init(project='one-shot-flowers', \n","           entity='kmotyka2000org', \n","           id='je1ey2wg', \n","           resume='must')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-04T17:47:48.674870Z","iopub.status.busy":"2024-05-04T17:47:48.674105Z","iopub.status.idle":"2024-05-04T17:48:24.210426Z","shell.execute_reply":"2024-05-04T17:48:24.209328Z","shell.execute_reply.started":"2024-05-04T17:47:48.674836Z"},"trusted":true},"outputs":[],"source":["run = wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"one-shot-flowers\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-04T17:48:40.793604Z","iopub.status.busy":"2024-05-04T17:48:40.793191Z","iopub.status.idle":"2024-05-04T17:49:04.578291Z","shell.execute_reply":"2024-05-04T17:49:04.577233Z","shell.execute_reply.started":"2024-05-04T17:48:40.793565Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","entity = \"kmotyka2000org\"\n","project = \"one-shot-flowers\"\n","artifact_name = \"model-legendary-fleet-4\"\n","epoch = \"latest\"\n","\n","artifact = run.use_artifact(f'{entity}/{project}/{artifact_name}:{epoch}')\n","\n","# Download the model\n","artifact_dir = artifact.download()\n","\n","# Load the model\n","model = tf.keras.models.load_model(artifact_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-04T17:49:55.901440Z","iopub.status.busy":"2024-05-04T17:49:55.900514Z","iopub.status.idle":"2024-05-04T17:49:59.418428Z","shell.execute_reply":"2024-05-04T17:49:59.417030Z","shell.execute_reply.started":"2024-05-04T17:49:55.901405Z"},"trusted":true},"outputs":[],"source":["model = tf.keras.models.load_model('/kaggle/input/no-aug-best/tensorflow2/no-aug-model/1/model-best.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Grad-CAM visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T14:58:07.992886Z","iopub.status.busy":"2024-05-19T14:58:07.991959Z","iopub.status.idle":"2024-05-19T14:58:21.324662Z","shell.execute_reply":"2024-05-19T14:58:21.323410Z","shell.execute_reply.started":"2024-05-19T14:58:07.992858Z"},"trusted":true},"outputs":[],"source":["!pip install tf_keras_vis\n","from tf_keras_vis.gradcam import Gradcam, GradcamPlusPlus\n","from tf_keras_vis.utils.scores import CategoricalScore\n","from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:03:03.499903Z","iopub.status.busy":"2024-05-19T16:03:03.499122Z","iopub.status.idle":"2024-05-19T16:03:05.670011Z","shell.execute_reply":"2024-05-19T16:03:05.668746Z","shell.execute_reply.started":"2024-05-19T16:03:03.499868Z"},"trusted":true},"outputs":[],"source":["!mkdir /kaggle/working/gradcam\n","!mkdir /kaggle/working/gradcam_plusplus"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T16:03:05.673320Z","iopub.status.busy":"2024-05-19T16:03:05.672847Z","iopub.status.idle":"2024-05-19T16:03:05.681928Z","shell.execute_reply":"2024-05-19T16:03:05.680869Z","shell.execute_reply.started":"2024-05-19T16:03:05.673274Z"},"trusted":true},"outputs":[],"source":["test_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T17:08:49.473428Z","iopub.status.busy":"2024-05-19T17:08:49.473031Z","iopub.status.idle":"2024-05-19T17:23:55.054336Z","shell.execute_reply":"2024-05-19T17:23:55.053133Z","shell.execute_reply.started":"2024-05-19T17:08:49.473397Z"},"trusted":true},"outputs":[],"source":["for index, x_df in test_df.reset_index().iterrows():\n","    # Load image\n","    score = CategoricalScore(x_df.target if x_df.target != 102 else 0)\n","    image = image_decoder(x_df.filepath, with_labels=False)\n","\n","    # Batch\n","    batch_image = tf.expand_dims(image, 0)\n","    \n","    # Predict\n","    pred = model.predict(batch_image)\n","    \n","    gradcam = Gradcam(model, model_modifier=ReplaceToLinear(), clone=False) \n","\n","    cam = gradcam(score, batch_image, penultimate_layer=-1)\n","\n","    heatmap = cam[0]\n","    \n","    # Normalize\n","    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n","    \n","    heatmap = np.uint8(255 * heatmap)\n","    image = np.uint8(255 * image)\n","    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    # Overlay the heatmap on the original image\n","    superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n","\n","    # Display the original image, heatmap, and superimposed image\n","    plt.figure(figsize=(5, 5))\n","\n","    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n","    plt.title(f'Grad-CAM: pred:: {np.argmax(pred, axis=1)[0]}, real: {x_df.target if x_df.target != 102 else 0}')\n","    plt.savefig(f'/kaggle/working/gradcam/GradCAM_{index}.png')\n","    plt.close()\n","    \n","#     break\n","!zip -r /kaggle/working/gradcam.zip /kaggle/working/gradcam\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T17:23:55.056981Z","iopub.status.busy":"2024-05-19T17:23:55.056653Z","iopub.status.idle":"2024-05-19T17:38:45.587916Z","shell.execute_reply":"2024-05-19T17:38:45.586665Z","shell.execute_reply.started":"2024-05-19T17:23:55.056947Z"},"trusted":true},"outputs":[],"source":["for index, x_df in test_df.reset_index().iterrows():\n","    # Load image\n","    score = CategoricalScore(x_df.target if x_df.target != 102 else 0)\n","    image = image_decoder(x_df.filepath, with_labels=False)\n","\n","    # Batch\n","    batch_image = tf.expand_dims(image, 0)\n","    \n","    # Predict\n","    pred = model.predict(batch_image)\n","    \n","    gradcam = GradcamPlusPlus(model, model_modifier=ReplaceToLinear(), clone=False) \n","\n","    cam = gradcam(score, batch_image, penultimate_layer=-1)\n","\n","    heatmap = cam[0]\n","    \n","    # Normalize\n","    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n","    \n","    heatmap = np.uint8(255 * heatmap)\n","    image = np.uint8(255 * image)\n","    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    # Overlay the heatmap on the original image\n","    superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n","\n","    # Display the original image, heatmap, and superimposed image\n","    plt.figure(figsize=(5, 5))\n","\n","    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n","    plt.title(f'Grad-CAM: pred:: {np.argmax(pred, axis=1)[0]}, real: {x_df.target if x_df.target != 102 else 0}')\n","    plt.savefig(f'/kaggle/working/gradcam_plusplus/GradCAM_{index}.png')\n","    plt.close()\n","    \n","#     break\n","!zip -r /kaggle/working/gradcam_plusplus.zip /kaggle/working/gradcam_plusplus\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":76785,"sourceId":2271054,"sourceType":"datasetVersion"},{"datasetId":4521589,"sourceId":7736740,"sourceType":"datasetVersion"},{"modelInstanceId":36225,"sourceId":43132,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
