{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Oxford 102 Flowers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:17:39.809397Z","iopub.status.busy":"2024-05-21T18:17:39.808997Z","iopub.status.idle":"2024-05-21T18:17:59.456885Z","shell.execute_reply":"2024-05-21T18:17:59.455590Z","shell.execute_reply.started":"2024-05-21T18:17:39.809366Z"},"trusted":true},"outputs":[],"source":["!pip install wandb==0.16"]},{"cell_type":"markdown","metadata":{},"source":["## Import packages, set configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-21T18:41:05.485463Z","iopub.status.busy":"2024-05-21T18:41:05.484538Z","iopub.status.idle":"2024-05-21T18:41:05.502907Z","shell.execute_reply":"2024-05-21T18:41:05.501707Z","shell.execute_reply.started":"2024-05-21T18:41:05.485428Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","import os\n","import matplotlib.pyplot as plt\n","import random\n","import json\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","from PIL import Image\n","import tensorflow.keras.backend as K\n","import tensorflow_probability as tfp\n","from scipy.stats import beta\n","import pickle \n","\n","class CFG:\n","    # Directories\n","    DIR_NAME = '/kaggle/input/pytorch-challange-flower-dataset/dataset/'\n","    TRAIN_DIR = os.path.join(DIR_NAME, 'train')\n","    VAL_DIR = os.path.join(DIR_NAME, 'valid')\n","    TEST_DIR = os.path.join(DIR_NAME, 'test')\n","    \n","    # Images\n","    CNN_INPUT_HEIGHT = 224\n","    CNN_INPUT_WIDTH = 224\n","    CNN_INPUT_SIZE = (CNN_INPUT_HEIGHT, CNN_INPUT_WIDTH)\n","    CNN_INPUT_CHANNELS = 3\n","    CNN_INPUT_SHAPE = (CNN_INPUT_HEIGHT, CNN_INPUT_WIDTH, CNN_INPUT_CHANNELS)\n","    \n","    # Categories\n","    CATEGORIES_JSON_PATH = '/kaggle/input/pytorch-challange-flower-dataset/cat_to_name.json'\n","    \n","    with open(CATEGORIES_JSON_PATH) as f:\n","        CATEGORIES = json.load(f)\n","    CATEGORIES = {int(k): v for k,v in CATEGORIES.items()}\n","    \n","    # Dataset\n","    BATCH_SIZE = 32\n","    TRAIN_SET_SIZE = 6552\n","    \n","    # Dataset Augmentation\n","    AUGMENT = True\n","    TRADITIONAL_AUG_PROB = 0.4\n","    \n","    MIXUP_PROB = 0 # 0.4\n","    MIXUP_ALPHA = 0.4\n","\n","    CUTMIX_PROB = 0 # 0.4\n","    CUTMIX_ALPHA = 1\n","    \n","    # Seeding\n","    SEED = 32\n","    \n","    # Model settings\n","    NETWORK_NAME = \"ResNet\"\n","    optimizer = \"Adam\"\n","    loss =\"CCE\"\n","    lr = 1e-5 # For Optimizer\n","    label_smoothing=0.0 # For loss (CCE)\n","    \n","    # Training\n","    NUM_SPLITS = 5\n","#     SELECTED_FOLDS = [0]\n","    DROP_REMAINDER = True # Drop remainder - dropping last batch if size < batch size\n","    EPOCHS = 35\n","    \n","    # Training monitoring\n","    PLOT_HISTORY = True\n","    \n","def seeding(SEED):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    tf.random.set_seed(SEED)\n","    print('seeding done!!!')\n","    \n","seeding(CFG.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["## Login to WANDB to log trainings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T19:36:07.157078Z","iopub.status.busy":"2024-05-21T19:36:07.155851Z","iopub.status.idle":"2024-05-21T19:36:07.309896Z","shell.execute_reply":"2024-05-21T19:36:07.308766Z","shell.execute_reply.started":"2024-05-21T19:36:07.157027Z"},"trusted":true},"outputs":[],"source":["import wandb\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T19:36:08.521124Z","iopub.status.busy":"2024-05-21T19:36:08.520357Z","iopub.status.idle":"2024-05-21T19:36:08.527688Z","shell.execute_reply":"2024-05-21T19:36:08.526498Z","shell.execute_reply.started":"2024-05-21T19:36:08.521089Z"},"trusted":true},"outputs":[],"source":["wandb_config={\n","    \"architecture\": CFG.NETWORK_NAME,\n","    \"input_shape\": CFG.CNN_INPUT_SHAPE,\n","    \"epochs\": CFG.EPOCHS,\n","    \"batch_size\": CFG.BATCH_SIZE,\n","    \"seed\": CFG.SEED,\n","    \"use_small_sample\": False, \n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:23:26.398632Z","iopub.status.busy":"2024-05-21T21:23:26.397776Z","iopub.status.idle":"2024-05-21T21:23:57.400896Z","shell.execute_reply":"2024-05-21T21:23:57.399778Z","shell.execute_reply.started":"2024-05-21T21:23:26.398590Z"},"trusted":true},"outputs":[],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"flowers-augmentation\",\n","\n","    # track hyperparameters and run metadata with wandb.config\n","    config=wandb_config\n",")\n","\n","wandb.log({\n","        \"Augment\": CFG.AUGMENT,\n","        \"Traditional Prob\": CFG.TRADITIONAL_AUG_PROB,\n","        \"MixUp Prob\": CFG.MIXUP_PROB,\n","        \"MixUp Alpha\": CFG.MIXUP_ALPHA,\n","        \"CutMix Prob\": CFG.CUTMIX_PROB,\n","        \"CutMix Alpha\": CFG.CUTMIX_ALPHA,\n","    })"]},{"cell_type":"markdown","metadata":{},"source":["## Load datasets"]},{"cell_type":"markdown","metadata":{},"source":["### Loading whole dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Extract all images from source dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:19:56.028838Z","iopub.status.busy":"2024-05-21T18:19:56.028063Z","iopub.status.idle":"2024-05-21T18:20:05.177776Z","shell.execute_reply":"2024-05-21T18:20:05.176647Z","shell.execute_reply.started":"2024-05-21T18:19:56.028798Z"},"trusted":true},"outputs":[],"source":["import tarfile \n","\n","if not os.path.isdir('/kaggle/working/flowers-102-source-extracted'):\n","    with tarfile.open('/kaggle/input/oxford-flowers-102-source/102flowers.tgz') as f: \n","        f.extractall('/kaggle/working/flowers-102-source-extracted') "]},{"cell_type":"markdown","metadata":{},"source":["#### Load whole dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:20:05.179859Z","iopub.status.busy":"2024-05-21T18:20:05.179438Z","iopub.status.idle":"2024-05-21T18:20:13.106158Z","shell.execute_reply":"2024-05-21T18:20:13.104432Z","shell.execute_reply.started":"2024-05-21T18:20:05.179823Z"},"trusted":true},"outputs":[],"source":["from scipy.io import loadmat\n","\n","labels_mine = loadmat('/kaggle/input/oxford-flowers-102-source/imagelabels.mat')[\"labels\"][0]\n","\n","DIR_PATH = '/kaggle/working/flowers-102-source-extracted/jpg'\n","\n","df_all = pd.DataFrame(columns=[\"filepath\", \"target\", \"targetName\"])\n","idx = 0\n","for image, label in zip(sorted(os.listdir(DIR_PATH)), labels_mine):\n","    new_row = pd.DataFrame({\"filepath\": os.path.join(DIR_PATH, image),\n","                            \"target\": label,\n","                           \"targetName\": CFG.CATEGORIES[label]}, \n","                               index=[idx])\n","    \n","    df_all = pd.concat([df_all, new_row], ignore_index=True)\n","    \n","    idx += 1\n","    \n","df_all[\"target\"] = df_all[\"target\"].astype(int)\n","print(df_all.head())\n","print(df_all.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Train-Test Split"]},{"cell_type":"markdown","metadata":{},"source":["#### Divide into Training and Test split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:20:13.108129Z","iopub.status.busy":"2024-05-21T18:20:13.107700Z","iopub.status.idle":"2024-05-21T18:20:13.302669Z","shell.execute_reply":"2024-05-21T18:20:13.301454Z","shell.execute_reply.started":"2024-05-21T18:20:13.108089Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming `df` is your DataFrame\n","# Splitting the DataFrame into train and test sets, stratified by the 'target' column\n","train_df, test_df = train_test_split(\n","    df_all, \n","    test_size=0.2,  # 20% for testing, 80% for training\n","    stratify=df_all['target'],  # Stratify by the 'target' column to maintain class distribution\n","    random_state=CFG.SEED  # For reproducibility\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Divide Training set into Folds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:20:13.306339Z","iopub.status.busy":"2024-05-21T18:20:13.305563Z","iopub.status.idle":"2024-05-21T18:20:13.344357Z","shell.execute_reply":"2024-05-21T18:20:13.343268Z","shell.execute_reply.started":"2024-05-21T18:20:13.306296Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","\n","skf = StratifiedKFold(n_splits=CFG.NUM_SPLITS, shuffle=True, random_state=CFG.SEED)\n","\n","df = train_df.reset_index(drop=True)\n","\n","df[\"fold\"] = -1\n","for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n","    df.loc[val_idx, 'fold'] = fold\n","    \n","# Apply the conversion logic\n","df['split'] = df['fold'].apply(lambda x: 'val' if x == 0 else 'train')\n","\n","# Drop the original 'fold' column and rename it to 'split'\n","df = df.drop('fold', axis=1)\n","\n","# Display or save the updated DataFrame\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize 10 random images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:20:13.348033Z","iopub.status.busy":"2024-05-21T18:20:13.347350Z","iopub.status.idle":"2024-05-21T18:20:13.356637Z","shell.execute_reply":"2024-05-21T18:20:13.355382Z","shell.execute_reply.started":"2024-05-21T18:20:13.347994Z"},"trusted":true},"outputs":[],"source":["def display_10_images(dataset):\n","\n","    images = dataset.sample(10, random_state=CFG.SEED)\n","\n","    plt.figure(figsize=(15, 6))  # Increase figure size for better visibility\n","    i = 0\n","    for _, image in images.iterrows():\n","        plt.subplot(2, 5, i + 1)  # 2 rows, 5 columns, ith+1 subplot\n","        plt.imshow(Image.open(image.filepath))\n","        plt.title(f'Class: {image.targetName}')\n","        plt.axis('off')\n","        i += 1\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:20:13.358744Z","iopub.status.busy":"2024-05-21T18:20:13.358298Z","iopub.status.idle":"2024-05-21T18:20:14.875212Z","shell.execute_reply":"2024-05-21T18:20:14.874287Z","shell.execute_reply.started":"2024-05-21T18:20:13.358708Z"},"trusted":true},"outputs":[],"source":["display_10_images(df)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["### Traditional Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:36:44.647065Z","iopub.status.busy":"2024-05-21T18:36:44.646355Z","iopub.status.idle":"2024-05-21T18:36:59.900972Z","shell.execute_reply":"2024-05-21T18:36:59.899740Z","shell.execute_reply.started":"2024-05-21T18:36:44.647029Z"},"trusted":true},"outputs":[],"source":["!pip install tensorflow_addons"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:23:14.198546Z","iopub.status.busy":"2024-05-21T21:23:14.198150Z","iopub.status.idle":"2024-05-21T21:23:14.210085Z","shell.execute_reply":"2024-05-21T21:23:14.209028Z","shell.execute_reply.started":"2024-05-21T21:23:14.198516Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","def random_rotate_image(image):\n","    # Generate a random angle for rotation. The angle is in radians.\n","    # Here, we rotate between -45 and 45 degrees, converted to radians.\n","    angle_rad = tf.random.uniform(shape=[], minval=-0.25*np.pi, maxval=0.25*np.pi)\n","    # Rotate the image\n","    rotated_image = tfa.image.rotate(image, angles=angle_rad, interpolation='NEAREST', fill_mode='reflect')\n","    return rotated_image\n","\n","# Generats random float\n","def random_float(shape=[], minval=0.0, maxval=1.0):\n","    rnd = tf.random.uniform(shape=shape, minval=minval, maxval=maxval, dtype=tf.float32)\n","    return rnd\n","\n","def traditional_image_aug(image):\n","#     # Flipping left right\n","#     image = tf.image.random_flip_left_right(image)\n","    \n","    # Brightness\n","    image = tf.image.random_brightness(image, max_delta=0.23)\n","    \n","    # Contrast\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    \n","    # Gaussian Filter\n","    image = tfa.image.gaussian_filter2d(image, filter_shape=(3, 3), sigma=1.0)\n","    \n","    # Rotate max 45 degrees\n","    image = random_rotate_image(image)\n","    \n","    # Add gaussian noise\n","    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.03, dtype=tf.float32)\n","    image = image + noise \n","    \n","    # Random Cropping \n","    max_ratio = random_float(minval=0.8, maxval=1.0)\n","    new_height = int(CFG.CNN_INPUT_HEIGHT * max_ratio)\n","    new_width = int(CFG.CNN_INPUT_WIDTH * max_ratio)\n","    image = tf.image.random_crop(image, size=[new_height, new_width, CFG.CNN_INPUT_CHANNELS])\n","    image = tf.image.resize(image, [CFG.CNN_INPUT_HEIGHT, CFG.CNN_INPUT_WIDTH])\n","\n","    return image\n","\n","def traditional_image_augmenter(with_labels=True):\n","    def augment(image):\n","        if random_float() <= CFG.TRADITIONAL_AUG_PROB:\n","            image = traditional_image_aug(image)\n","        return image\n","\n","    def augment_with_labels(image, label):\n","        return augment(image), label\n","\n","    return augment_with_labels if with_labels else augment"]},{"cell_type":"markdown","metadata":{},"source":["### Advanced Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["#### MixUp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:37:24.924631Z","iopub.status.busy":"2024-05-21T18:37:24.923577Z","iopub.status.idle":"2024-05-21T18:37:24.934216Z","shell.execute_reply":"2024-05-21T18:37:24.933123Z","shell.execute_reply.started":"2024-05-21T18:37:24.924571Z"},"trusted":true},"outputs":[],"source":["def mixup_image_aug(images, labels, alpha=CFG.MIXUP_ALPHA):\n","    \n","    if random_float() > CFG.MIXUP_PROB:\n","        return images, labels\n","    \n","    image_shape = tf.shape(images)\n","    label_shape = tf.shape(labels)\n","\n","    beta = tfp.distributions.Beta(alpha, alpha)\n","    lam = beta.sample(1)[0]\n","\n","    images = lam * images + (1 - lam) * tf.roll(images, shift=1, axis=0)\n","    labels = lam * labels + (1 - lam) * tf.roll(labels, shift=1, axis=0)\n","\n","    images = tf.reshape(images, image_shape)\n","    labels = tf.reshape(labels, label_shape)\n","    \n","    return images, labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### CutMix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:37:26.844088Z","iopub.status.busy":"2024-05-21T18:37:26.843679Z","iopub.status.idle":"2024-05-21T18:37:26.866871Z","shell.execute_reply":"2024-05-21T18:37:26.865630Z","shell.execute_reply.started":"2024-05-21T18:37:26.844060Z"},"trusted":true},"outputs":[],"source":["\n","import tensorflow as tf\n","\n","\n","\n","def create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size):\n","    # Create a grid of coordinates (height x width)\n","    x_coords = tf.range(width)\n","    y_coords = tf.range(height)\n","    Y, X = tf.meshgrid(y_coords, x_coords)\n","\n","    # Reshape the bounding box coordinates to make them broadcastable over the batch size\n","    bbx1 = tf.reshape(bbx1, [batch_size, 1, 1])\n","    bby1 = tf.reshape(bby1, [batch_size, 1, 1])\n","    bbx2 = tf.reshape(bbx2, [batch_size, 1, 1])\n","    bby2 = tf.reshape(bby2, [batch_size, 1, 1])\n","\n","    # Create the mask by comparing the coordinates\n","    mask = (X >= bbx1) & (X < bbx2) & (Y >= bby1) & (Y < bby2)\n","    mask = tf.cast(mask, tf.float32)  # Convert the mask to float32\n","    \n","    # Calculate ratio \n","    patch_area = tf.reduce_sum(mask, axis=[1, 2])  # Sum over height, width, and channels dimensions\n","    total_area = height * width\n","    ratio = patch_area / tf.cast(total_area, tf.float32)\n","    ratio = tf.expand_dims(ratio, -1)\n","    ratio = tf.tile(ratio, [1, 102])\n","    # Add the channel dimension\n","    mask = tf.expand_dims(mask, -1)\n","    # Tile the mask across the channel dimension\n","    mask = tf.tile(mask, [1, 1, 1, channels])\n","    \n","    \n","    return mask, ratio\n","\n","\n","def cutmix(images, labels, probability=0.5, alpha=1.0):\n","    # Only apply CutMix with the given probability\n","    if random_float() > probability:\n","        return images, labels\n","\n","    # Assume images is a 4D tensor of shape [batch_size, height, width, channels]\n","    shape = tf.shape(images)\n","    \n","    batch_size = shape[0]\n","    height = shape[1]\n","    width = shape[2]\n","    channels = shape[3]\n","    \n","    # Sample lambda and calculate patch dimensions\n","    beta = tfp.distributions.Beta(alpha, alpha)\n","    lambda_val = beta.sample(1)\n","#     beta_distribution = beta(alpha, alpha)\n","#     lambda_val = beta_distribution.rvs(size=1)[0]\n","\n","\n","    cut_rat = tf.sqrt(1. - lambda_val)\n","    \n","    cut_w = tf.cast(width, tf.float32) * cut_rat\n","    cut_w = tf.cast(cut_w, tf.int32)  # Now, cut_w is an int32 tensor.\n","    \n","    cut_h = tf.cast(height, tf.float32) * cut_rat\n","    cut_h = tf.cast(cut_h, tf.int32)  # Now, cut_h is an int32 tensor.\n","    \n","    # Uniformly sample the center of the patch\n","    cx = tf.random.uniform([batch_size], minval=0, maxval=width, dtype=tf.int32)\n","    cy = tf.random.uniform([batch_size], minval=0, maxval=height, dtype=tf.int32)\n","    \n","    # Calculate the patch coordinates\n","    bbx1 = tf.clip_by_value(cx - cut_w // 2, 0, width)\n","    bby1 = tf.clip_by_value(cy - cut_h // 2, 0, height)\n","    bbx2 = tf.clip_by_value(cx + cut_w // 2, 0, width)\n","    bby2 = tf.clip_by_value(cy + cut_h // 2, 0, height)\n","    \n","#     # Create mask\n","    mask, ratio = create_cutmix_mask(bbx1, bby1, bbx2, bby2, height, width, channels, batch_size)\n","    indices = tf.random.shuffle(tf.range(batch_size))\n","    mixed_images = images * mask + tf.gather(images, indices) * (1 - mask)\n","\n","    # Mix the labels\n","    mixed_labels = labels * ratio + tf.gather(labels, indices) * (1 - ratio)\n","#     mixed_labels = labels\n","    \n","    return mixed_images, mixed_labels\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"markdown","metadata":{},"source":["### Define metrics, loss, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:38:27.120543Z","iopub.status.busy":"2024-05-21T18:38:27.120125Z","iopub.status.idle":"2024-05-21T18:38:27.132970Z","shell.execute_reply":"2024-05-21T18:38:27.131444Z","shell.execute_reply.started":"2024-05-21T18:38:27.120511Z"},"trusted":true},"outputs":[],"source":["import sklearn.metrics\n","\n","def get_metrics():\n","    auc = tf.keras.metrics.AUC(curve='PR', name='auc', multi_label=False) # auc on prcision-recall curve\n","    acc = tf.keras.metrics.CategoricalAccuracy(name='acc')\n","    return [acc, auc]\n","\n","def padded_cmap(y_true, y_pred, padding_factor=5):\n","    num_classes = y_true.shape[1]\n","    pad_rows = np.array([[1]*num_classes]*padding_factor)\n","    y_true = np.concatenate([y_true, pad_rows])\n","    y_pred = np.concatenate([y_pred, pad_rows])\n","    score = sklearn.metrics.average_precision_score(y_true, y_pred, average='macro',)\n","    return score\n","\n","def get_loss():\n","    if CFG.loss==\"CCE\":\n","        loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=CFG.label_smoothing)\n","    else:\n","        raise ValueError(\"Loss not found\")\n","    return loss\n","    \n","def get_optimizer():\n","    if CFG.optimizer == \"Adam\":\n","        opt = tf.keras.optimizers.Adam(learning_rate=CFG.lr)\n","    else:\n","        raise ValueError(\"Optmizer not found\")\n","    return opt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:38:45.176665Z","iopub.status.busy":"2024-05-21T18:38:45.175608Z","iopub.status.idle":"2024-05-21T18:38:45.187922Z","shell.execute_reply":"2024-05-21T18:38:45.186658Z","shell.execute_reply.started":"2024-05-21T18:38:45.176619Z"},"trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","def build_model_resnet(CFG, compile_model=True):\n","    \"\"\"\n","    Builds and returns a model based on the specified configuration.\n","    \"\"\"\n","  \n","    DIM = (None, None)\n","\n","    # Base model - Resnet50\n","    base = tf.keras.applications.ResNet50(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","\n","    # Input layer \n","    inp = tf.keras.layers.Input(shape=(*DIM, 3))\n","\n","    # Input -> base \n","    out = base(inp)\n","\n","    # GAP Layer\n","    out = tf.keras.layers.GlobalAveragePooling2D()(out)\n","\n","    # Final dense layer for classification\n","    out = tf.keras.layers.Dense(len(CFG.CATEGORIES), activation='softmax')(out)\n","\n","    # Create the TensorFlow model \n","    model = tf.keras.Model(inputs=inp, outputs=out)\n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:41:56.557600Z","iopub.status.busy":"2024-05-19T11:41:56.557316Z","iopub.status.idle":"2024-05-19T11:42:00.707623Z","shell.execute_reply":"2024-05-19T11:42:00.706435Z","shell.execute_reply.started":"2024-05-19T11:41:56.557578Z"},"trusted":true},"outputs":[],"source":["m = build_model_resnet(CFG)\n","\n","m.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:38:50.841262Z","iopub.status.busy":"2024-05-21T18:38:50.840863Z","iopub.status.idle":"2024-05-21T18:38:50.853471Z","shell.execute_reply":"2024-05-21T18:38:50.852289Z","shell.execute_reply.started":"2024-05-21T18:38:50.841231Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","\n","def build_flattened_model_resnet(CFG, compile_model=True):\n","\n","    DIM = (None, None)\n","    # Load the base ResNet50 model without the top classification layers\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(*DIM, 3))\n","\n","    # Make sure all layers are set to trainable for fine-tuning\n","    for layer in base_model.layers:\n","        layer.trainable = True\n","\n","    # Add custom layers on top of ResNet50\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(len(CFG.CATEGORIES), activation='softmax', name='output_layer')(x)  # Change the number of units and activation based on your task\n","\n","    # Create the complete model\n","    model = Model(inputs=base_model.input, outputs=x)\n","\n","    # Print the model summary\n","    \n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:42:00.723628Z","iopub.status.busy":"2024-05-19T11:42:00.723172Z","iopub.status.idle":"2024-05-19T11:42:02.553854Z","shell.execute_reply":"2024-05-19T11:42:02.552657Z","shell.execute_reply.started":"2024-05-19T11:42:00.723594Z"},"trusted":true},"outputs":[],"source":["m = build_flattened_model_resnet(CFG)\n","\n","# m.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:38:54.563757Z","iopub.status.busy":"2024-05-21T18:38:54.563342Z","iopub.status.idle":"2024-05-21T18:38:54.575243Z","shell.execute_reply":"2024-05-21T18:38:54.573649Z","shell.execute_reply.started":"2024-05-21T18:38:54.563724Z"},"trusted":true},"outputs":[],"source":["def build_flattened_model_efficientnet(CFG, compile_model=True):\n","\n","    DIM = (None, None)\n","    # Load the base ResNet50 model without the top classification layers\n","    base_model = tf.keras.applications.EfficientNetB4(\n","      include_top=False,\n","      weights=\"imagenet\",\n","      input_shape=(*DIM, 3),\n","    )\n","\n","    # Make sure all layers are set to trainable for fine-tuning\n","    for layer in base_model.layers:\n","        layer.trainable = True\n","\n","    # Add custom layers on top of ResNet50\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(len(CFG.CATEGORIES), activation='softmax', name='output_layer')(x)  # Change the number of units and activation based on your task\n","\n","    # Create the complete model\n","    model = Model(inputs=base_model.input, outputs=x)\n","\n","    # Print the model summary\n","    \n","    if compile_model:\n","        # Optimizer\n","        opt = get_optimizer()\n","        # Loss function\n","        loss = get_loss()\n","        # Evaluation metrics\n","        metrics = get_metrics()\n","        # Compile the model \n","        model.compile(optimizer=opt,\n","                      loss=loss,\n","                      metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:42:02.568139Z","iopub.status.busy":"2024-05-19T11:42:02.567085Z","iopub.status.idle":"2024-05-19T11:42:08.088505Z","shell.execute_reply":"2024-05-19T11:42:08.087444Z","shell.execute_reply.started":"2024-05-19T11:42:02.568106Z"},"trusted":true},"outputs":[],"source":["m = build_flattened_model_efficientnet(CFG)\n","\n","# m.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Train model using cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:38:59.993320Z","iopub.status.busy":"2024-05-21T18:38:59.992903Z","iopub.status.idle":"2024-05-21T18:39:00.007034Z","shell.execute_reply":"2024-05-21T18:39:00.005851Z","shell.execute_reply.started":"2024-05-21T18:38:59.993288Z"},"trusted":true},"outputs":[],"source":["def image_decoder(path, label=None, with_labels=True):\n","    def image_loader(path):\n","        if not os.path.exists(path):\n","            pass\n","        image = tf.io.read_file(path)\n","        image = tf.image.decode_jpeg(image, channels=3)\n","        image = tf.cast(image, tf.float32)\n","        image = tf.image.resize(image, CFG.CNN_INPUT_SIZE)\n","        image = image / 255.0\n","        \n","        image.set_shape([CFG.CNN_INPUT_HEIGHT, CFG.CNN_INPUT_WIDTH, CFG.CNN_INPUT_CHANNELS])\n","        \n","        return image\n","    \n","    def target_loader(target):\n","#         target = tf.reshape(target, [1])\n","        target = tf.cast(tf.one_hot(target, depth=len(CFG.CATEGORIES)), dtype=tf.float32)\n","        return target #tf.reshape(target, [len(CFG.CATEGORIES)])\n","\n","    def decode(path):\n","        image = image_loader(path)\n","        return image\n","\n","    def decode_with_labels(path, label):\n","        label = target_loader(label)\n","        return decode(path), label\n","    if type(path) == str:\n","        return decode_with_labels(path, label) if with_labels else decode(path)\n","    return decode_with_labels(path.numpy(), label.numpy()) if with_labels else decode(path.numpy())\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:39:01.898520Z","iopub.status.busy":"2024-05-21T18:39:01.897823Z","iopub.status.idle":"2024-05-21T18:39:01.918741Z","shell.execute_reply":"2024-05-21T18:39:01.917390Z","shell.execute_reply.started":"2024-05-21T18:39:01.898475Z"},"trusted":true},"outputs":[],"source":["def build_dataset(paths, labels=None, batch_size=CFG.BATCH_SIZE, target_size=CFG.CNN_INPUT_SIZE,\n","                  image_decoder_fn=None, traditional_augment_fn=None,\n","                  spec_decode_fn=None, mixup_image_augment_fn=None,\n","                  cache=True, cache_dir=\"\",drop_remainder=False,\n","                  augment=True, repeat=True, shuffle=100):\n","    \"\"\"\n","    Creates a TensorFlow dataset from the given paths and labels.\n","\n","    Args:\n","        paths (list): A list of file paths to the audio files.\n","        labels (list): A list of corresponding labels for the audio files.\n","        batch_size (int): Batch size for the created dataset.\n","        target_size (list): A list of target image size for the spectrograms.\n","        audio_decode_fn (function): A function to decode the audio file.\n","        audio_augment_fn (function): A function to augment the audio file.\n","        spec_decode_fn (function): A function to decode the spectrogram.\n","        spec_augment_fn (function): A function to augment the spectrogram.\n","        cache (bool): Whether to cache the dataset or not.\n","        cache_dir (str): Directory path to cache the dataset.\n","        drop_remainder (bool): Whether to drop the last batch if it is smaller than batch_size.\n","        augment (bool): Whether to augment the dataset or not.\n","        repeat (bool): Whether to repeat the dataset or not.\n","        shuffle (int): Number of elements from the dataset to buffer for shuffling.\n","\n","    Returns:\n","        ds (tf.data.Dataset): A TensorFlow dataset.\n","    \"\"\"\n","\n","    if traditional_augment_fn is None:\n","        traditional_augment_fn = traditional_image_augmenter(\n","            labels is not None)\n","        \n","\n","    AUTO = tf.data.experimental.AUTOTUNE\n","\n","\n","    slices = paths if labels is None else (paths, labels)\n","    ds = tf.data.Dataset.from_tensor_slices(slices)\n","\n","    if labels is None:\n","        ds = ds.map(lambda x: tf.py_function(image_decoder, [x], [tf.float32]), num_parallel_calls=AUTO)\n","    else:\n","        ds = ds.map(lambda x, y: tf.py_function(image_decoder, [x, y], [tf.float32, tf.float32]), num_parallel_calls=AUTO)\n","    \n","\n","#     ds = ds.cache(cache_dir) if cache else ds\n","\n","    ds = ds.repeat() if repeat else ds\n","\n","#     opt = tf.data.Options()\n","\n","    if shuffle:\n","        ds = ds.shuffle(shuffle, seed=CFG.SEED)\n","#         opt.experimental_deterministic = False\n","\n","\n","\n","    ds = ds.map(traditional_augment_fn, num_parallel_calls=AUTO) if augment else ds\n","\n","    ds = ds.batch(batch_size, drop_remainder=CFG.DROP_REMAINDER)\n","\n","    ds = ds.map(mixup_image_aug, num_parallel_calls=AUTO) if augment else ds # if (augment and labels is not None) else ds\n","    \n","    ds = ds.map(lambda images, labels: cutmix(images, labels, probability=CFG.CUTMIX_PROB, alpha=CFG.CUTMIX_ALPHA), num_parallel_calls=AUTO) if augment else ds\n","\n","    ds = ds.prefetch(AUTO)\n","    return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:39:04.375544Z","iopub.status.busy":"2024-05-21T18:39:04.375154Z","iopub.status.idle":"2024-05-21T18:39:04.391741Z","shell.execute_reply":"2024-05-21T18:39:04.390451Z","shell.execute_reply.started":"2024-05-21T18:39:04.375513Z"},"trusted":true},"outputs":[],"source":["def plot_history(history):\n","    \"\"\"Plot trainign history, credit: @cdeotte\"\"\"\n","    epochs = len(history.history['auc'])\n","    plt.figure(figsize=(15,5))\n","    plt.plot(np.arange(epochs),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n","    plt.plot(np.arange(epochs),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n","    x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n","    plt.ylabel('AUC (PR)',size=14); plt.xlabel('Epoch',size=14)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(epochs),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n","    plt2.plot(np.arange(epochs),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n","    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n","    plt.ylabel('Loss',size=14)\n","    plt.title('Fold %i - Training Plot'%(fold+1),size=18)\n","    plt.legend(loc=3)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## WANDB Logging"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T11:42:08.142048Z","iopub.status.busy":"2024-05-19T11:42:08.141791Z","iopub.status.idle":"2024-05-19T11:42:09.176859Z","shell.execute_reply":"2024-05-19T11:42:09.174854Z","shell.execute_reply.started":"2024-05-19T11:42:08.142028Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T18:39:07.638475Z","iopub.status.busy":"2024-05-21T18:39:07.638071Z","iopub.status.idle":"2024-05-21T18:39:07.663834Z","shell.execute_reply":"2024-05-21T18:39:07.662551Z","shell.execute_reply.started":"2024-05-21T18:39:07.638444Z"},"trusted":true},"outputs":[],"source":["from wandb.keras import WandbCallback\n","\n","\n","def train_val_test_fit(model, df, CFG, model_name=\"Model\"):\n","    # Split dataset with cv filter\n","    train_df = df.query(\"split == 'train'\").reset_index(drop=True) \n","    valid_df = df.query(\"split=='val'\").reset_index(drop=True) \n","\n","    # Get file paths and labels\n","    train_paths = train_df.filepath.values; train_labels = train_df.target.values\n","    valid_paths = valid_df.filepath.values; valid_labels = valid_df.target.values\n","\n","\n","    # Shuffle the file paths and labels\n","    index = np.arange(len(train_paths))\n","    np.random.shuffle(index)\n","    train_paths  = train_paths[index]\n","    train_labels = train_labels[index]\n","\n","    # Compute the number of training and validation samples\n","    num_train = len(train_paths); num_valid = len(valid_paths)\n","        \n","    # # Build the training and validation datasets\n","    cache=True\n","    train_ds = build_dataset(train_paths, train_labels, \n","                              batch_size=CFG.BATCH_SIZE, cache=cache, shuffle=True,\n","                            augment=CFG.AUGMENT, drop_remainder=CFG.DROP_REMAINDER)\n","    valid_ds = build_dataset(valid_paths, valid_labels,\n","                              batch_size=CFG.BATCH_SIZE, cache=cache, shuffle=False,\n","                              augment=False, repeat=False, drop_remainder=CFG.DROP_REMAINDER)\n","\n","\n","    # # Print information about the training\n","    print('#### Image Size: (%i, %i) | Model: %s | Batch Size: %i '%\n","          (*CFG.CNN_INPUT_SIZE, model_name, CFG.BATCH_SIZE))\n","    print('#### Num Train: {:,} | Num Valid: {:,}'.format(len(train_paths), len(valid_paths)))\n","\n","    # # Callbacks\n","    sv = tf.keras.callbacks.ModelCheckpoint(\n","        'training_save.keras', monitor='val_acc', verbose=0, save_best_only=True,\n","        save_weights_only=False, mode='max', save_freq='epoch')\n","    callbacks = [sv,  \n","                 WandbCallback(generator=valid_ds)] # get_lr_callback(CFG.batch_size)\n","\n","    # # Training\n","    print('# Training')\n","    history = model.fit(\n","        train_ds, \n","        epochs=CFG.EPOCHS, \n","        callbacks=callbacks, \n","        steps_per_epoch=len(train_paths)//CFG.BATCH_SIZE,\n","        validation_data=valid_ds, \n","        # verbose=CFG.verbose,\n","    )\n","    \n","    model = tf.keras.models.load_model('/kaggle/working/training_save.keras')\n","    \n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-21T21:23:57.403076Z","iopub.status.busy":"2024-05-21T21:23:57.402712Z"},"trusted":true},"outputs":[],"source":[" # # Clear the session, build and train the model\n","K.clear_session()\n","# model = build_model_resnet(CFG) \n","model = build_model_resnet(CFG)\n","model, history = train_val_test_fit(model, df, CFG, model_name=\"ResNet\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Predict on Test Set"]},{"cell_type":"markdown","metadata":{},"source":["#### Prediction utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:20:42.203120Z","iopub.status.busy":"2024-05-21T21:20:42.202470Z","iopub.status.idle":"2024-05-21T21:20:42.210100Z","shell.execute_reply":"2024-05-21T21:20:42.209072Z","shell.execute_reply.started":"2024-05-21T21:20:42.203086Z"},"trusted":true},"outputs":[],"source":["def predict_classes(model, paths):\n","    fake_labels = np.zeros(test_paths.shape, dtype=int)\n","    ds = build_dataset(paths, fake_labels,\n","                    batch_size=1, cache=False, shuffle=False,\n","                    augment=False, repeat=False, drop_remainder=False)\n","\n","    preds = model.predict(ds)\n","    pred_labels = np.argmax(preds, axis=1)\n","\n","    return pred_labels, preds"]},{"cell_type":"markdown","metadata":{},"source":["#### Predict and calculate score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:20:42.211666Z","iopub.status.busy":"2024-05-21T21:20:42.211367Z","iopub.status.idle":"2024-05-21T21:20:42.230550Z","shell.execute_reply":"2024-05-21T21:20:42.229490Z","shell.execute_reply.started":"2024-05-21T21:20:42.211642Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def log_test_metrics(test_labels, preds):\n","    accuracy = accuracy_score(test_labels, preds)\n","    precision = precision_score(test_labels, preds, average='weighted') \n","    recall = recall_score(test_labels, preds, average='weighted') \n","    f1 = f1_score(test_labels, preds, average='weighted')  \n","\n","\n","    wandb.log({\n","        \"Test Accuracy\": accuracy,\n","        \"Test Precision\": precision,\n","        \"Test Recall\": recall,\n","        \"Test F1 Score\": f1\n","    })\n","\n","    print(f\"Accuracy: {accuracy} Precision: {precision} Recall: {recall} F1: {f1}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:20:42.232719Z","iopub.status.busy":"2024-05-21T21:20:42.232369Z","iopub.status.idle":"2024-05-21T21:20:59.828121Z","shell.execute_reply":"2024-05-21T21:20:59.826763Z","shell.execute_reply.started":"2024-05-21T21:20:42.232681Z"},"trusted":true},"outputs":[],"source":["test_paths = test_df.filepath.values; test_labels = test_df.target.values\n","\n","preds, probs = predict_classes(model, test_paths)\n","\n","log_test_metrics(test_labels, preds)"]},{"cell_type":"markdown","metadata":{},"source":["#### WANDB: Log confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:22:14.953761Z","iopub.status.busy":"2024-05-21T21:22:14.952817Z","iopub.status.idle":"2024-05-21T21:22:16.003181Z","shell.execute_reply":"2024-05-21T21:22:16.002128Z","shell.execute_reply.started":"2024-05-21T21:22:14.953723Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def create_top_10_confusion_matrix(true_labels, preds, class_names):\n","    # Assuming adjusted_labels and adjusted_preds are properly defined\n","    num_classes = len(class_names)  # Total number of classes\n","    class_labels = range(num_classes)  # Zero-based class labels\n","    \n","    adjusted_labels = test_labels - 1\n","    adjusted_preds = preds - 1\n","    adjusted_categories = {k-1: v for k, v in CFG.CATEGORIES.items()}\n","\n","    # Create the full confusion matrix with adjusted labels\n","    full_cm = confusion_matrix(adjusted_labels, adjusted_preds, labels=class_labels)\n","\n","    # Calculate misclassification counts (not including correct classifications)\n","    misclassification_counts = full_cm.sum(axis=1) - np.diag(full_cm)\n","    total_true_counts = np.bincount(adjusted_labels, minlength=num_classes)\n","    misclassification_rates = misclassification_counts / total_true_counts\n","\n","    # Identify top 10 most frequently misclassified classes\n","    top_10_classes = np.argsort(-misclassification_rates)[:10]\n","\n","    # Create reduced confusion matrix for top 10 classes\n","    top_10_cm = full_cm[top_10_classes, :][:, top_10_classes]\n","\n","    # Calculate \"Other\" row and column properly\n","    total_predictions_sum = full_cm.sum(axis=0)[top_10_classes]  # All predictions sum\n","    total_true_sum = full_cm.sum(axis=1)[top_10_classes]  # All true labels sum\n","    other_row = total_predictions_sum - top_10_cm.sum(axis=0)\n","    other_column = total_true_sum - top_10_cm.sum(axis=1)\n","\n","    # Append the \"Other\" value\n","    other_value = np.nan\n","    \n","    # Forming the 11x11 confusion matrix\n","    final_cm = np.vstack([\n","        np.hstack([top_10_cm, other_column.reshape(-1, 1)]),\n","        np.hstack([other_row, other_value])\n","    ])\n","\n","    # Labels for plotting (adjust labels back to 1-102 for readability)\n","    labels = [f'{CFG.CATEGORIES[i+1]}' for i in top_10_classes] + ['Other']\n","\n","    # Plotting\n","    plt.figure(figsize=(12, 10))\n","    sns.heatmap(final_cm, annot=True, cmap=\"Blues\", fmt=\".0f\", xticklabels=labels, yticklabels=labels)\n","    plt.title('Confusion Matrix for Top 10 Most Frequently Misclassified Categories')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.savefig(\"confusion_matrix.png\")\n","    plt.show()\n","    \n","    return final_cm\n","\n","top_10_cm = create_top_10_confusion_matrix(test_labels, preds, CFG.CATEGORIES)\n","wandb.log({\"Top 10 Confusion Matrix\": wandb.Image(\"confusion_matrix.png\")})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T20:30:02.511472Z","iopub.status.busy":"2024-05-21T20:30:02.511067Z","iopub.status.idle":"2024-05-21T20:30:02.526487Z","shell.execute_reply":"2024-05-21T20:30:02.525073Z","shell.execute_reply.started":"2024-05-21T20:30:02.511443Z"},"trusted":true},"outputs":[],"source":["def plot_batch(batch, row=3, col=3):\n","    \"\"\"Plot one batch data\"\"\"\n","    if isinstance(batch, tuple) or isinstance(batch, list):\n","        imgs, tars = batch\n","    else:\n","        imgs = batch\n","        tars = None\n","    plt.figure(figsize=(col*2, row*2))\n","    \n","    for idx in range(row*col):\n","        ax = plt.subplot(row, col, idx+1)\n","        ax.imshow(imgs[idx])\n","        plt.axis('off')\n","\n","        if tars is not None:\n","            label = tars[idx].numpy().argmax()\n","            if label == 0:\n","                label = 102\n","            name = CFG.CATEGORIES[label]\n","            plt.title(name)\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:28:31.571958Z","iopub.status.busy":"2024-05-19T12:28:31.570993Z","iopub.status.idle":"2024-05-19T12:28:33.541377Z","shell.execute_reply":"2024-05-19T12:28:33.540274Z","shell.execute_reply.started":"2024-05-19T12:28:31.571925Z"},"trusted":true},"outputs":[],"source":["DESIRED_BATCH = 3\n","ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=False, cache=False, shuffle=None)\n","ds = ds.take(100)\n","ds_iter = iter(ds)\n","\n","for idx, (imgs, labels) in enumerate(ds_iter):\n","    if idx == DESIRED_BATCH:\n","        plot_batch((imgs, labels), 2, 5)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ds = build_dataset(df.filepath.tolist(), df.target.tolist(), augment=True, cache=False, shuffle=None)\n","ds = ds.take(100)\n","ds_iter = iter(ds)\n","\n","for idx, (imgs, labels) in enumerate(ds_iter):\n","    if idx == DESIRED_BATCH:\n","        plot_batch((imgs, labels), 2, 5)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:22:21.730182Z","iopub.status.busy":"2024-05-21T21:22:21.729769Z","iopub.status.idle":"2024-05-21T21:22:30.043174Z","shell.execute_reply":"2024-05-21T21:22:30.042375Z","shell.execute_reply.started":"2024-05-21T21:22:21.730150Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## Load model from wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T21:21:13.434649Z","iopub.status.busy":"2024-05-17T21:21:13.434189Z","iopub.status.idle":"2024-05-17T21:21:17.864976Z","shell.execute_reply":"2024-05-17T21:21:17.864142Z","shell.execute_reply.started":"2024-05-17T21:21:13.434627Z"},"trusted":true},"outputs":[],"source":["import wandb\n","\n","wandb.login(key=\"ed6c2fc334f7ae297c94626b3056901c86359321\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T21:21:45.191978Z","iopub.status.busy":"2024-05-17T21:21:45.191420Z","iopub.status.idle":"2024-05-17T21:21:47.777828Z","shell.execute_reply":"2024-05-17T21:21:47.777089Z","shell.execute_reply.started":"2024-05-17T21:21:45.191957Z"},"trusted":true},"outputs":[],"source":["wandb.init(project='flowers-augmentation', \n","           entity='kmotyka2000org', \n","           id='igzrho7g', \n","           resume='must')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T21:25:43.241991Z","iopub.status.busy":"2024-05-17T21:25:43.241679Z","iopub.status.idle":"2024-05-17T21:26:23.575953Z","shell.execute_reply":"2024-05-17T21:26:23.574927Z","shell.execute_reply.started":"2024-05-17T21:25:43.241969Z"},"trusted":true},"outputs":[],"source":["run = wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"flowers-augmentation\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T21:26:23.578649Z","iopub.status.busy":"2024-05-17T21:26:23.578259Z","iopub.status.idle":"2024-05-17T21:26:47.327803Z","shell.execute_reply":"2024-05-17T21:26:47.326932Z","shell.execute_reply.started":"2024-05-17T21:26:23.578619Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","entity = \"kmotyka2000org\"\n","project = \"flowers-augmentation\"\n","artifact_name = \"model-driven-haze-21\"\n","epoch = \"latest\"\n","\n","artifact = run.use_artifact(f'{entity}/{project}/{artifact_name}:{epoch}')\n","\n","# Download the model\n","artifact_dir = artifact.download()\n","\n","# Load the model\n","model = tf.keras.models.load_model(artifact_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = tf.keras.models.load_model('/kaggle/input/no-aug-best/tensorflow2/no-aug-model/1/model-best.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:09:31.095453Z","iopub.status.busy":"2024-05-14T10:09:31.095077Z","iopub.status.idle":"2024-05-14T10:09:36.006656Z","shell.execute_reply":"2024-05-14T10:09:36.005697Z","shell.execute_reply.started":"2024-05-14T10:09:31.095426Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["### GradCAM"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:28:46.316517Z","iopub.status.busy":"2024-05-19T12:28:46.316121Z","iopub.status.idle":"2024-05-19T12:28:59.212571Z","shell.execute_reply":"2024-05-19T12:28:59.211538Z","shell.execute_reply.started":"2024-05-19T12:28:46.316486Z"},"trusted":true},"outputs":[],"source":["!pip install tf_keras_vis\n","from tf_keras_vis.gradcam import Gradcam, GradcamPlusPlus\n","from tf_keras_vis.utils.scores import CategoricalScore\n","from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:35:28.742425Z","iopub.status.busy":"2024-05-18T14:35:28.741960Z","iopub.status.idle":"2024-05-18T14:35:28.752593Z","shell.execute_reply":"2024-05-18T14:35:28.751409Z","shell.execute_reply.started":"2024-05-18T14:35:28.742375Z"},"trusted":true},"outputs":[],"source":["samples_20 = test_df.sample(20, random_state=CFG.SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T23:00:36.947740Z","iopub.status.busy":"2024-05-17T23:00:36.946920Z","iopub.status.idle":"2024-05-17T23:00:37.426460Z","shell.execute_reply":"2024-05-17T23:00:37.422929Z","shell.execute_reply.started":"2024-05-17T23:00:36.947707Z"},"trusted":true},"outputs":[],"source":["x_df = samples_20.sample(1, random_state=CFG.SEED)\n","\n","print(x_df)\n","score = CategoricalScore(x_df.target.values[0])\n","image = image_decoder(x_df.filepath.values[0], with_labels=False)\n","\n","# Batch\n","batch_image = tf.expand_dims(image, 0)\n","\n","pred = model.predict(batch_image)\n","\n","print(f\"Predicted: {np.argmax(pred, axis=1)[0]}, real: {x_df.target.values[0]}\")\n","\n","plt.imshow(image)\n","plt.title(CFG.CATEGORIES[x_df.target.values[0]])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T23:00:43.252022Z","iopub.status.busy":"2024-05-17T23:00:43.251318Z","iopub.status.idle":"2024-05-17T23:00:44.243882Z","shell.execute_reply":"2024-05-17T23:00:44.242368Z","shell.execute_reply.started":"2024-05-17T23:00:43.251986Z"},"trusted":true},"outputs":[],"source":["gradcam = GradcamPlusPlus(model, model_modifier=ReplaceToLinear(), clone=False) \n","\n","cam = gradcam(score, batch_image, penultimate_layer=-1)\n","\n","# Since the image is a single input, we'll get the heatmap for the first image\n","heatmap = cam[0]\n","\n","# Normalize the heatmap to [0, 1] range for better visualization\n","heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n","\n","# Visualize the heatmap\n","plt.imshow(heatmap)\n","plt.title('Grad-CAM Heatmap')\n","plt.colorbar()\n","plt.show()\n","\n","\n","# Visualize\n","heatmap = np.uint8(255 * heatmap)\n","image = np.uint8(255 * image)\n","heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","# Overlay the heatmap on the original image\n","superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n","\n","# Display the original image, heatmap, and superimposed image\n","plt.figure(figsize=(5, 5))\n","\n","plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n","plt.title('Grad-CAM Overlay')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T22:52:48.093226Z","iopub.status.busy":"2024-05-17T22:52:48.092801Z","iopub.status.idle":"2024-05-17T22:52:48.421208Z","shell.execute_reply":"2024-05-17T22:52:48.419949Z","shell.execute_reply.started":"2024-05-17T22:52:48.093193Z"},"trusted":true},"outputs":[],"source":["example = test_df[test_df[\"target\"] == 73].sample(1)\n","plt.imshow(image_decoder(example.filepath.values[0], with_labels=False))\n","plt.title(CFG.CATEGORIES[example.target.values[0]])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:29:12.824397Z","iopub.status.busy":"2024-05-19T12:29:12.823391Z","iopub.status.idle":"2024-05-19T12:29:13.892717Z","shell.execute_reply":"2024-05-19T12:29:13.891320Z","shell.execute_reply.started":"2024-05-19T12:29:12.824357Z"},"trusted":true},"outputs":[],"source":["!mkdir /kaggle/working/gradcam"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for index, x_df in test_df.reset_index().iterrows():\n","    # Load image\n","    score = CategoricalScore(x_df.target if x_df.target != 102 else 0)\n","    image = image_decoder(x_df.filepath, with_labels=False)\n","\n","    # Batch\n","    batch_image = tf.expand_dims(image, 0)\n","    \n","    # Predict\n","    pred = model.predict(batch_image)\n","    \n","    gradcam = Gradcam(model, model_modifier=ReplaceToLinear(), clone=False) \n","\n","    cam = gradcam(score, batch_image, penultimate_layer=-1)\n","\n","    heatmap = cam[0]\n","    \n","    # Normalize\n","    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n","    \n","    heatmap = np.uint8(255 * heatmap)\n","    image = np.uint8(255 * image)\n","    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    # Overlay the heatmap on the original image\n","    superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n","\n","    # Display the original image, heatmap, and superimposed image\n","    plt.figure(figsize=(5, 5))\n","\n","    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n","    plt.title(f'Grad-CAM: pred:: {np.argmax(pred, axis=1)[0]}, real: {x_df.target if x_df.target != 102 else 0}')\n","    plt.savefig(f'/kaggle/working/gradcam/GradCAM_{index}.png')\n","    plt.close()\n","    \n","#     break\n","!zip -r /kaggle/working/gradcam.zip /kaggle/working/gradcam\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for index, x_df in test_df.reset_index().iterrows():\n","    # Load image\n","    score = CategoricalScore(x_df.target if x_df.target != 102 else 0)\n","    image = image_decoder(x_df.filepath, with_labels=False)\n","\n","    # Batch\n","    batch_image = tf.expand_dims(image, 0)\n","    \n","    # Predict\n","    pred = model.predict(batch_image)\n","    \n","    gradcam = GradcamPlusPlus(model, model_modifier=ReplaceToLinear(), clone=False) \n","\n","    cam = gradcam(score, batch_image, penultimate_layer=-1)\n","\n","    heatmap = cam[0]\n","    \n","    # Normalize\n","    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n","    \n","    heatmap = np.uint8(255 * heatmap)\n","    image = np.uint8(255 * image)\n","    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","\n","    # Overlay the heatmap on the original image\n","    superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n","\n","    # Display the original image, heatmap, and superimposed image\n","    plt.figure(figsize=(5, 5))\n","\n","    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n","    plt.title(f'Grad-CAM: pred:: {np.argmax(pred, axis=1)[0]}, real: {x_df.target if x_df.target != 102 else 0}')\n","    plt.savefig(f'/kaggle/working/gradcam_plusplus/GradCAM_{index}.png')\n","    plt.close()\n","    \n","#     break\n","!zip -r /kaggle/working/gradcam_plusplus.zip /kaggle/working/gradcam_plusplus\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:04:09.963966Z","iopub.status.busy":"2024-05-19T13:04:09.963159Z","iopub.status.idle":"2024-05-19T13:04:11.101575Z","shell.execute_reply":"2024-05-19T13:04:11.096232Z","shell.execute_reply.started":"2024-05-19T13:04:09.963928Z"},"trusted":true},"outputs":[],"source":["!mkdir /kaggle/working/processed_images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for index, x_df in test_df.reset_index().iterrows():\n","\n","\n","    image = image_decoder(x_df.filepath, with_labels=False)\n","\n","\n","    # Display the original image, heatmap, and superimposed image\n","    plt.figure(figsize=(5, 5))\n","\n","    plt.imshow(image)\n","    plt.title(f'Class: {CFG.CATEGORIES[x_df.target]}')\n","    plt.savefig(f'/kaggle/working/processed_images/image_{index}.png')\n","    plt.close()\n","    \n","!zip -r /kaggle/working/processed_images.zip /kaggle/working/processed_images\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":76785,"sourceId":2271054,"sourceType":"datasetVersion"},{"datasetId":4521589,"sourceId":7736740,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":36225,"sourceId":43132,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
